{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install requirements and prepare environment","metadata":{}},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:31:32.026730Z","iopub.execute_input":"2023-08-06T15:31:32.027150Z","iopub.status.idle":"2023-08-06T15:31:47.611196Z","shell.execute_reply.started":"2023-08-06T15:31:32.027121Z","shell.execute_reply":"2023-08-06T15:31:47.609995Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.65.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom sklearn.model_selection import train_test_split\nfrom time import time\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import accuracy_score\nimport os\nimport pandas as pd\nimport gc\nimport random\nimport pickle\nimport gdown\nimport json\nimport string\nfrom zipfile import ZipFile\nfrom torch.nn.functional import cosine_similarity\nfrom tabulate import tabulate\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:31:47.615302Z","iopub.execute_input":"2023-08-06T15:31:47.615617Z","iopub.status.idle":"2023-08-06T15:31:51.582189Z","shell.execute_reply.started":"2023-08-06T15:31:47.615588Z","shell.execute_reply":"2023-08-06T15:31:51.581165Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:31:51.583464Z","iopub.execute_input":"2023-08-06T15:31:51.584091Z","iopub.status.idle":"2023-08-06T15:31:51.619417Z","shell.execute_reply.started":"2023-08-06T15:31:51.584053Z","shell.execute_reply":"2023-08-06T15:31:51.618328Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"url = \"https://drive.google.com/file/d/1-4nIaIx2i0_WWks7neqRhoYaq43VdDGP/view?usp=sharing\"\noutput = \"pretrained_embeddings.zip\"\ngdown.download(url, output, quiet=False, fuzzy=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-30T13:17:14.773366Z","iopub.execute_input":"2023-07-30T13:17:14.773963Z","iopub.status.idle":"2023-07-30T13:17:50.620095Z","shell.execute_reply.started":"2023-07-30T13:17:14.773929Z","shell.execute_reply":"2023-07-30T13:17:50.619022Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (uriginal): https://drive.google.com/uc?id=1-4nIaIx2i0_WWks7neqRhoYaq43VdDGP\nFrom (redirected): https://drive.google.com/uc?id=1-4nIaIx2i0_WWks7neqRhoYaq43VdDGP&confirm=t&uuid=de58dfbc-6dcf-4fcd-8dd2-c076b05bda49\nTo: /kaggle/working/pretrained_embeddings.zip\n100%|██████████| 602M/602M [00:32<00:00, 18.3MB/s] \n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'pretrained_embeddings.zip'"},"metadata":{}}]},{"cell_type":"code","source":"url = \"https://drive.google.com/file/d/1-3KQTJYaAJRc5nluH20FLhaXY2a1m0Q-/view?usp=sharing\"\noutput = \"pretrained_embeddings_common_voice.pkl\"\ngdown.download(url, output, quiet=False, fuzzy=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-30T13:19:41.828372Z","iopub.execute_input":"2023-07-30T13:19:41.828766Z","iopub.status.idle":"2023-07-30T13:20:30.186480Z","shell.execute_reply.started":"2023-07-30T13:19:41.828736Z","shell.execute_reply":"2023-07-30T13:20:30.185385Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (uriginal): https://drive.google.com/uc?id=1-3KQTJYaAJRc5nluH20FLhaXY2a1m0Q-\nFrom (redirected): https://drive.google.com/uc?id=1-3KQTJYaAJRc5nluH20FLhaXY2a1m0Q-&confirm=t&uuid=551e51b7-1c8a-4e2c-83ef-be9b652e79ed\nTo: /kaggle/working/pretrained_embeddings_common_voice.pkl\n100%|██████████| 624M/624M [00:45<00:00, 13.8MB/s] \n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'pretrained_embeddings_common_voice.pkl'"},"metadata":{}}]},{"cell_type":"code","source":"url = \"https://drive.google.com/file/d/1lMXC-H60waEU9z9XlfOZeui9EmvMKvZR/view?usp=sharing\"\noutput = \"metadata.json\"\ngdown.download(url, output, quiet=False, fuzzy=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-30T13:20:30.188594Z","iopub.execute_input":"2023-07-30T13:20:30.188961Z","iopub.status.idle":"2023-07-30T13:20:37.777890Z","shell.execute_reply.started":"2023-07-30T13:20:30.188929Z","shell.execute_reply":"2023-07-30T13:20:37.777005Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1lMXC-H60waEU9z9XlfOZeui9EmvMKvZR\nTo: /kaggle/working/metadata.json\n100%|██████████| 10.9M/10.9M [00:01<00:00, 10.8MB/s]\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'metadata.json'"},"metadata":{}}]},{"cell_type":"code","source":"url = \"https://drive.google.com/file/d/15cZ84V52tKQrtr4dVnGqf1p0tHxxK3jR/view?usp=sharing\"\noutput = \"fleurs_data.pkl\"\ngdown.download(url, output, quiet=False, fuzzy=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-30T13:20:37.779304Z","iopub.execute_input":"2023-07-30T13:20:37.779638Z","iopub.status.idle":"2023-07-30T13:20:46.802610Z","shell.execute_reply.started":"2023-07-30T13:20:37.779607Z","shell.execute_reply":"2023-07-30T13:20:46.801553Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=15cZ84V52tKQrtr4dVnGqf1p0tHxxK3jR\nTo: /kaggle/working/fleurs_data.pkl\n100%|██████████| 41.2M/41.2M [00:04<00:00, 9.35MB/s]\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'fleurs_data.pkl'"},"metadata":{}}]},{"cell_type":"code","source":"with ZipFile('pretrained_embeddings.zip', 'r') as zipObj:\n    zipObj.extractall('pretrained_embeddings')","metadata":{"execution":{"iopub.status.busy":"2023-07-30T13:20:46.804928Z","iopub.execute_input":"2023-07-30T13:20:46.805361Z","iopub.status.idle":"2023-07-30T13:20:47.808683Z","shell.execute_reply.started":"2023-07-30T13:20:46.805327Z","shell.execute_reply":"2023-07-30T13:20:47.807680Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"with open('metadata.json', 'r') as f:\n    metadata_brown = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:55:20.572532Z","iopub.execute_input":"2023-07-31T13:55:20.572935Z","iopub.status.idle":"2023-07-31T13:55:20.774125Z","shell.execute_reply.started":"2023-07-31T13:55:20.572906Z","shell.execute_reply":"2023-07-31T13:55:20.772917Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# open files in pretrained_embeddings\n# 0 audio - 1 image - 2 text\nbrown_data = {}\nfor i in range(1, 11):\n    with open(f'pretrained_embeddings/pretrained_embeddings_part{i}.pkl', 'rb') as f:\n        brown_data.update(pickle.load(f))","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:55:21.515478Z","iopub.execute_input":"2023-07-31T13:55:21.515840Z","iopub.status.idle":"2023-07-31T13:55:38.578895Z","shell.execute_reply.started":"2023-07-31T13:55:21.515810Z","shell.execute_reply":"2023-07-31T13:55:38.577658Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"len(brown_data)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:55:38.581067Z","iopub.execute_input":"2023-07-31T13:55:38.581590Z","iopub.status.idle":"2023-07-31T13:55:38.590150Z","shell.execute_reply.started":"2023-07-31T13:55:38.581551Z","shell.execute_reply":"2023-07-31T13:55:38.589013Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"54785"},"metadata":{}}]},{"cell_type":"code","source":"random_key = random.choice(list(metadata_brown.keys()))\nprint(random_key)\nprint(metadata_brown[random_key])","metadata":{"execution":{"iopub.status.busy":"2023-07-31T12:01:05.884757Z","iopub.execute_input":"2023-07-31T12:01:05.885147Z","iopub.status.idle":"2023-07-31T12:01:05.898961Z","shell.execute_reply.started":"2023-07-31T12:01:05.885094Z","shell.execute_reply":"2023-07-31T12:01:05.898011Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"17872\n{'id': 17872, 'file_path': 'dataset/part4/audios/audio_17872.wav', 'text': 'The death of her mother in 1865 prevented this.', 'part_id': 4}\n","output_type":"stream"}]},{"cell_type":"code","source":"random_key = random.choice(list(brown_data.keys()))\nprint(random_key)\nprint(metadata_brown[str(random_key)])","metadata":{"execution":{"iopub.status.busy":"2023-07-31T12:04:22.453718Z","iopub.execute_input":"2023-07-31T12:04:22.454875Z","iopub.status.idle":"2023-07-31T12:04:22.462741Z","shell.execute_reply.started":"2023-07-31T12:04:22.454828Z","shell.execute_reply":"2023-07-31T12:04:22.461717Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"8752\n{'id': 8752, 'file_path': 'dataset/part2/audios/audio_8752.wav', 'text': 'The only other regions so blessed are the British Isles , western Europe , eastern China , southern Chile and parts of Japan , New Zealand and Tasmania.', 'part_id': 2}\n","output_type":"stream"}]},{"cell_type":"code","source":"with open(f'pretrained_embeddings_common_voice.pkl', 'rb') as f:\n    common_voice_data = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:55:38.591672Z","iopub.execute_input":"2023-07-31T13:55:38.592691Z","iopub.status.idle":"2023-07-31T13:55:57.179358Z","shell.execute_reply.started":"2023-07-31T13:55:38.592656Z","shell.execute_reply":"2023-07-31T13:55:57.178271Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"random_key = random.choice(list(common_voice_data['train'].keys()))\nprint(random_key)\ncommon_voice_data['train'][random_key]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(common_voice_data['train']))\nprint(len(common_voice_data['validation']))\nprint(len(common_voice_data['test']))","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:55:57.208962Z","iopub.execute_input":"2023-07-31T13:55:57.209292Z","iopub.status.idle":"2023-07-31T13:55:57.215107Z","shell.execute_reply.started":"2023-07-31T13:55:57.209265Z","shell.execute_reply":"2023-07-31T13:55:57.214006Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"50000\n3492\n2197\n","output_type":"stream"}]},{"cell_type":"code","source":"with open(f'fleurs_data.pkl', 'rb') as f:\n    fleurs_data = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:55:57.216816Z","iopub.execute_input":"2023-07-31T13:55:57.217600Z","iopub.status.idle":"2023-07-31T13:55:58.289679Z","shell.execute_reply.started":"2023-07-31T13:55:57.217566Z","shell.execute_reply":"2023-07-31T13:55:58.288537Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"random_key = random.choice(list(fleurs_data['train'].keys()))\nprint(random_key)\nfleurs_data['train'][random_key]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(fleurs_data['train']) + len(common_voice_data['train']))\nprint(len(fleurs_data['validation']) + len(common_voice_data['validation']))\nprint(len(fleurs_data['test']) + len(common_voice_data['test']))\nprint(len(fleurs_data['train']) + len(common_voice_data['train']) + len(fleurs_data['validation']) + len(common_voice_data['validation']) + len(fleurs_data['test']) + len(common_voice_data['test']))","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:56:21.863483Z","iopub.execute_input":"2023-07-31T13:56:21.864160Z","iopub.status.idle":"2023-07-31T13:56:21.871395Z","shell.execute_reply.started":"2023-07-31T13:56:21.864122Z","shell.execute_reply":"2023-07-31T13:56:21.870240Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"52602\n3886\n2844\n59332\n","output_type":"stream"}]},{"cell_type":"code","source":"a = len(fleurs_data['train']) + len(common_voice_data['train']) + len(fleurs_data['validation']) + len(common_voice_data['validation']) + len(fleurs_data['test']) + len(common_voice_data['test'])\ntotal = a + len(brown_data)\nprint(total)\ntest_len = int(total * 0.1)\ntrain_len = int(total * 0.8) + 1\nprint(train_len)\nprint(total - train_len - test_len)\nval_len = total - train_len - test_len\nprint(test_len)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:56:23.694082Z","iopub.execute_input":"2023-07-31T13:56:23.695310Z","iopub.status.idle":"2023-07-31T13:56:23.704182Z","shell.execute_reply.started":"2023-07-31T13:56:23.695261Z","shell.execute_reply":"2023-07-31T13:56:23.703073Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"114117\n91294\n11412\n11411\n","output_type":"stream"}]},{"cell_type":"code","source":"train_num_brown = train_len - (len(fleurs_data['train']) + len(common_voice_data['train']))\nval_num_brown = val_len - (len(fleurs_data['validation']) + len(common_voice_data['validation']))\ntest_num_brown = test_len - (len(fleurs_data['test']) + len(common_voice_data['test']))\nprint(train_num_brown, val_num_brown, test_num_brown)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:56:28.806466Z","iopub.execute_input":"2023-07-31T13:56:28.807574Z","iopub.status.idle":"2023-07-31T13:56:28.814908Z","shell.execute_reply.started":"2023-07-31T13:56:28.807537Z","shell.execute_reply":"2023-07-31T13:56:28.813621Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"38692 7526 8567\n","output_type":"stream"}]},{"cell_type":"code","source":"# now select randomly with determined seed this numbers from brown dataset\nrandom.seed(42)\n\nall_brown = list(set(brown_data.keys()))\ntrain_brown = random.sample(all_brown, train_num_brown)\nremaining_brown = list(set(all_brown) - set(train_brown))\nval_brown = random.sample(list(set(remaining_brown) - set(train_brown)), val_num_brown)\ntest_brown = random.sample(list(set(all_brown) - set(train_brown) - set(val_brown)), test_num_brown)\n\nprint(len(train_brown), len(val_brown), len(test_brown))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:56:40.787594Z","iopub.execute_input":"2023-07-31T13:56:40.787968Z","iopub.status.idle":"2023-07-31T13:56:40.865877Z","shell.execute_reply.started":"2023-07-31T13:56:40.787935Z","shell.execute_reply":"2023-07-31T13:56:40.864809Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"38692 7526 8567\n","output_type":"stream"}]},{"cell_type":"code","source":"type(brown_data[train_brown[0]])","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:10:43.349031Z","iopub.execute_input":"2023-07-31T14:10:43.350115Z","iopub.status.idle":"2023-07-31T14:10:43.358082Z","shell.execute_reply.started":"2023-07-31T14:10:43.350071Z","shell.execute_reply":"2023-07-31T14:10:43.356965Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"list"},"metadata":{}}]},{"cell_type":"code","source":"total_train = {}\ntotal_train['audio'] = []\ntotal_train['pure-text'] = []\nfor i in train_brown:\n    x = brown_data[i][0]\n    if x.device != 'cpu':\n        x = x.cpu()\n    total_train['audio'].append(x)\n    total_train['pure-text'].append(metadata_brown[str(i)]['text'])\nfor value in common_voice_data['train'].values():\n    total_train['audio'].append(value['audio_embedding'])\n    total_train['pure-text'].append(value['text'])\nfor value in fleurs_data['train'].values():\n    total_train['audio'].append(value['audio_embedding'])\n    total_train['pure-text'].append(value['text'])\n\ntotal_train['text'] = []\nfor i in train_brown:\n    total_train['text'].append(torch.Tensor(brown_data[i][2]))\nfor value in common_voice_data['train'].values():\n    total_train['text'].append(value['text_embedding'])\nfor value in fleurs_data['train'].values():\n    total_train['text'].append(value['text_embedding'])\n\ntotal_train['image'] = []\nfor i in train_brown:\n    total_train['image'].append(brown_data[i][1])\nfor value in common_voice_data['train'].values():\n    total_train['image'].append(value['image_embedding'])\nfor value in fleurs_data['train'].values():\n    total_train['image'].append(value['image_embedding'])\n\n# shuffle them together\nindices = list(range(len(total_train['audio'])))\nrandom.shuffle(indices)\ntotal_train['audio'] = [total_train['audio'][i] for i in indices]\ntotal_train['text'] = [total_train['text'][i] for i in indices]\ntotal_train['image'] = [total_train['image'][i] for i in indices]\ntotal_train['pure-text'] = [total_train['pure-text'][i] for i in indices]\n\nprint(len(total_train['audio']), len(total_train['text']), len(total_train['image']), len(total_train['pure-text']))","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:11:51.849827Z","iopub.execute_input":"2023-07-31T14:11:51.850335Z","iopub.status.idle":"2023-07-31T14:11:52.811624Z","shell.execute_reply.started":"2023-07-31T14:11:51.850296Z","shell.execute_reply":"2023-07-31T14:11:52.810381Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"91294 91294 91294 91294\n","output_type":"stream"}]},{"cell_type":"code","source":"total_val = {}\ntotal_val['audio'] = []\ntotal_val['pure-text'] = []\n\nfor i in val_brown:\n    x = brown_data[i][0]\n    if x.device != 'cpu':\n        x = x.cpu()\n    total_val['audio'].append(x)\n    total_val['pure-text'].append(metadata_brown[str(i)]['text'])\nfor value in common_voice_data['validation'].values():\n    total_val['audio'].append(value['audio_embedding'])\n    total_val['pure-text'].append(value['text'])\nfor value in fleurs_data['validation'].values():\n    total_val['audio'].append(value['audio_embedding'])\n    total_val['pure-text'].append(value['text'])\ntotal_val['text'] = []\nfor i in val_brown:\n    total_val['text'].append(torch.Tensor(brown_data[i][2]))\nfor value in common_voice_data['validation'].values():\n    total_val['text'].append(value['text_embedding'])\nfor value in fleurs_data['validation'].values():\n    total_val['text'].append(value['text_embedding'])\n\ntotal_val['image'] = []\nfor i in val_brown:\n    total_val['image'].append(brown_data[i][1])\nfor value in common_voice_data['validation'].values():\n    total_val['image'].append(value['image_embedding'])\nfor value in fleurs_data['validation'].values():\n    total_val['image'].append(value['image_embedding'])\n    \n# shuffle them together\nindices = list(range(len(total_val['audio'])))\nrandom.shuffle(indices)\ntotal_val['audio'] = [total_val['audio'][i] for i in indices]\ntotal_val['text'] = [total_val['text'][i] for i in indices]\ntotal_val['image'] = [total_val['image'][i] for i in indices]\ntotal_val['pure-text'] = [total_val['pure-text'][i] for i in indices]\n\n\nprint(len(total_val['audio']), len(total_val['text']), len(total_val['image']), len(total_val['pure-text']))","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:12:38.304428Z","iopub.execute_input":"2023-07-31T14:12:38.304799Z","iopub.status.idle":"2023-07-31T14:12:38.486195Z","shell.execute_reply.started":"2023-07-31T14:12:38.304768Z","shell.execute_reply":"2023-07-31T14:12:38.485096Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"11412 11412 11412 11412\n","output_type":"stream"}]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:12:40.308610Z","iopub.execute_input":"2023-07-31T14:12:40.308989Z","iopub.status.idle":"2023-07-31T14:12:42.412908Z","shell.execute_reply.started":"2023-07-31T14:12:40.308958Z","shell.execute_reply":"2023-07-31T14:12:42.411684Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"13031"},"metadata":{}}]},{"cell_type":"code","source":"total_test = {}\ntotal_test['audio'] = []\ntotal_test['pure-text'] = []\nfor i in test_brown:\n    if type(brown_data[i][0]) == np.ndarray:\n        print(type(brown_data[i][0]))\n        print('audio - brown')\n    x = brown_data[i][0]\n    if x.device != 'cpu':\n        x = x.cpu()\n    total_test['audio'].append(x)\n    total_test['pure-text'].append(metadata_brown[str(i)]['text'])\n    # print(brown_data[i][0].device)\n    # print('audio - brown')\nfor value in common_voice_data['test'].values():\n    if type(value['audio_embedding']) == np.ndarray:\n        print(type(value['audio_embedding']))\n        print('audio - common_voice')\n    total_test['audio'].append(value['audio_embedding'])\n    total_test['pure-text'].append(value['text'])\n#     print(value['audio_embedding'].device)\n#     print('audio - common_voice')\nfor value in fleurs_data['test'].values():\n    if type(value['audio_embedding']) == np.ndarray:\n        print(type(value['audio_embedding']))\n        print('audio - fleurs')\n    total_test['audio'].append(value['audio_embedding'])\n    total_test['pure-text'].append(value['text'])\n#     print(value['audio_embedding'].device)\n#     print('audio - fleurs')\n\ntotal_test['text'] = []\nfor i in test_brown:\n#     if type(brown_data[i][2]) == np.ndarray:\n#         print(type(brown_data[i][2]))\n#         print('text - brown')\n    total_test['text'].append(torch.Tensor(brown_data[i][2]))\n    x = torch.Tensor(brown_data[i][2])\n#     print(x.device)\n#     print('text - brown')\nfor value in common_voice_data['test'].values():\n    if type(value['text_embedding']) == np.ndarray:\n        print(type(value['text_embedding']))\n        print('text - common_voice')\n    total_test['text'].append(value['text_embedding'])\n#     print(value['text_embedding'].device)\n#     print('text - common_voice')\nfor value in fleurs_data['test'].values():\n    if type(value['text_embedding']) == np.ndarray:\n        print(type(value['text_embedding']))\n        print('text - fleurs')\n    total_test['text'].append(value['text_embedding'])\n#     print(value['text_embedding'].device)\n#     print('text - fleurs')\n\ntotal_test['image'] = []\nfor i in test_brown:\n    if type(brown_data[i][1]) == np.ndarray:\n        print(type(brown_data[i][1]))\n        print('image - brown')\n    total_test['image'].append(brown_data[i][1])\n#     print(brown_data[i][1].device)\n#     print('image - brown')\nfor value in common_voice_data['test'].values():\n    if type(value['image_embedding']) == np.ndarray:\n        print(type(value['image_embedding']))\n        print('image - common_voice')\n    total_test['image'].append(value['image_embedding'])\n#     print(value['image_embedding'].device)\n#     print('image - common_voice')\n    \nfor value in fleurs_data['test'].values():\n    if type(value['image_embedding']) == np.ndarray:\n        print(type(value['image_embedding']))\n        print('image - fleurs')\n    total_test['image'].append(value['image_embedding'])\n#     print(value['image_embedding'].device)\n#     print('image - fleurs')\n    \n# shuffle them together\nindices = list(range(len(total_test['audio'])))\nrandom.shuffle(indices)\ntotal_test['audio'] = [total_test['audio'][i] for i in indices]\ntotal_test['text'] = [total_test['text'][i] for i in indices]\ntotal_test['image'] = [total_test['image'][i] for i in indices]\ntotal_test['pure-text'] = [total_test['pure-text'][i] for i in indices]\n\nprint(len(total_test['audio']), len(total_test['text']), len(total_test['image']), len(total_test['pure-text']))","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:13:15.089699Z","iopub.execute_input":"2023-07-31T14:13:15.090146Z","iopub.status.idle":"2023-07-31T14:13:15.277889Z","shell.execute_reply.started":"2023-07-31T14:13:15.090113Z","shell.execute_reply":"2023-07-31T14:13:15.276788Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"11411 11411 11411 11411\n","output_type":"stream"}]},{"cell_type":"code","source":"total_dataset = {}\ntotal_dataset['train'] = total_train\ntotal_dataset['validation'] = total_val\ntotal_dataset['test'] = total_test\n\nwith open('total_dataset_v1_with_text.pkl', 'wb') as f:\n    pickle.dump(total_dataset, f)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:13:24.672494Z","iopub.execute_input":"2023-07-31T14:13:24.672883Z","iopub.status.idle":"2023-07-31T14:13:58.019116Z","shell.execute_reply.started":"2023-07-31T14:13:24.672852Z","shell.execute_reply":"2023-07-31T14:13:58.017861Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"# with open('total_dataset.pkl', 'rb') as f:\n#     total_dataset = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:53:46.521913Z","iopub.execute_input":"2023-07-31T06:53:46.522461Z","iopub.status.idle":"2023-07-31T06:54:22.954514Z","shell.execute_reply.started":"2023-07-31T06:53:46.522418Z","shell.execute_reply":"2023-07-31T06:54:22.952071Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"len_train = len(total_dataset['train']['audio'])\nlen_val = len(total_dataset['validation']['audio'])\nlen_test = len(total_dataset['test']['audio'])\n\ntotal_audio_embeddings = total_dataset['train']['audio'] + total_dataset['validation']['audio'] + total_dataset['test']['audio']\ntotal_text_embeddings = total_dataset['train']['text'] + total_dataset['validation']['text'] + total_dataset['test']['text']\ntotal_image_embeddings = total_dataset['train']['image'] + total_dataset['validation']['image'] + total_dataset['test']['image']\n\ntotal_audio_embeddings = torch.stack(total_audio_embeddings)\ntotal_text_embeddings = torch.stack(total_text_embeddings)\ntotal_image_embeddings = torch.stack(total_image_embeddings)\n\n# normalizer each embedding tensor\nprint(total_image_embeddings.shape)\ntotal_audio_embeddings = F.normalize(total_audio_embeddings, dim=1)\ntotal_text_embeddings = F.normalize(total_text_embeddings, dim=1)\ntotal_image_embeddings = F.normalize(total_image_embeddings, dim=1)\n\n# turn it back to lists and split it\n# total_audio_embeddings = total_audio_embeddings.tolist()\n# total_text_embeddings = total_text_embeddings.tolist()\n# total_image_embeddings = total_image_embeddings.tolist()\n\naudio_embeddings_train = total_audio_embeddings[:len_train]\naudio_embeddings_val = total_audio_embeddings[len_train:len_train+len_val]\naudio_embeddings_test = total_audio_embeddings[len_train+len_val:]\n\n\n\ntext_embeddings_train = total_text_embeddings[:len_train]\ntext_embeddings_val = total_text_embeddings[len_train:len_train+len_val]\ntext_embeddings_test = total_text_embeddings[len_train+len_val:]\n\nimage_embeddings_train = total_image_embeddings[:len_train]\nimage_embeddings_val = total_image_embeddings[len_train:len_train+len_val]\nimage_embeddings_test = total_image_embeddings[len_train+len_val:]\n\n# with open('image_dataset_normalized.pkl', 'wb') as f:\n#     pickle.dump((image_embeddings_train, image_embeddings_val, image_embeddings_test), f)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:13:58.062779Z","iopub.execute_input":"2023-07-31T14:13:58.063136Z","iopub.status.idle":"2023-07-31T14:14:00.732054Z","shell.execute_reply.started":"2023-07-31T14:13:58.063106Z","shell.execute_reply":"2023-07-31T14:14:00.730857Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"torch.Size([114117, 1000])\n","output_type":"stream"}]},{"cell_type":"code","source":"total_dataset_v2 = {\n    'train': {\n        'audio': audio_embeddings_train,\n        'image': image_embeddings_train,\n        'text': total_dataset['train']['text'],\n        'pure-text': total_dataset['train']['pure-text']\n    },\n    'validation': {\n        'audio': audio_embeddings_val,\n        'image': image_embeddings_val,\n        'text': total_dataset['validation']['text'],\n        'pure-text': total_dataset['validation']['pure-text']\n    },\n    'test': {\n        'audio': audio_embeddings_test,\n        'image': image_embeddings_test,\n        'text': total_dataset['test']['text'],\n        'pure-text': total_dataset['test']['pure-text']\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:14:00.733790Z","iopub.execute_input":"2023-07-31T14:14:00.735298Z","iopub.status.idle":"2023-07-31T14:14:00.918818Z","shell.execute_reply.started":"2023-07-31T14:14:00.735257Z","shell.execute_reply":"2023-07-31T14:14:00.917717Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"# save the dataset\nwith open('total_dataset_v2_with_text.pkl', 'wb') as f:\n    pickle.dump(total_dataset_v2, f)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:14:00.951449Z","iopub.execute_input":"2023-07-31T14:14:00.951810Z","iopub.status.idle":"2023-07-31T14:14:20.276172Z","shell.execute_reply.started":"2023-07-31T14:14:00.951779Z","shell.execute_reply":"2023-07-31T14:14:20.274929Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('total_dataset_v2_with_text.pkl', 'rb') as f:\n    total_dataset = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:20:04.731396Z","iopub.execute_input":"2023-07-31T13:20:04.731840Z","iopub.status.idle":"2023-07-31T13:20:42.354490Z","shell.execute_reply.started":"2023-07-31T13:20:04.731802Z","shell.execute_reply":"2023-07-31T13:20:42.353344Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"# converts list of tensors to tensor\nlen_train = len(total_dataset['train']['audio'])\nlen_val = len(total_dataset['validation']['audio'])\nlen_test = len(total_dataset['test']['audio'])\n\ndel total_text_embeddings\ndel text_embeddings_train\ndel text_embeddings_val\ndel text_embeddings_test\n\n# total_audio_embeddings = total_dataset['train']['audio'] + total_dataset['validation']['audio'] + total_dataset['test']['audio']\n# total_text_embeddings = total_dataset['train']['text'] + total_dataset['validation']['text'] + total_dataset['test']['text']\ntotal_image_embeddings = total_dataset['train']['image'] + total_dataset['validation']['image'] + total_dataset['test']['image']\n\n# total_audio_embeddings = torch.stack(total_audio_embeddings)\n# total_text_embeddings = torch.stack(total_text_embeddings)\ntotal_image_embeddings = torch.stack(total_image_embeddings)\n\n# normalizer each embedding tensor\nprint(total_image_embeddings.shape)\n# total_audio_embeddings = F.normalize(total_audio_embeddings, dim=1)\n# total_text_embeddings = F.normalize(total_text_embeddings, dim=1)\ntotal_image_embeddings = F.normalize(total_image_embeddings, dim=1)\n\n# turn it back to lists and split it\n# total_audio_embeddings = total_audio_embeddings.tolist()\n# total_text_embeddings = total_text_embeddings.tolist()\n# total_image_embeddings = total_image_embeddings.tolist()\n\n# audio_embeddings_train = total_audio_embeddings[:len_train]\n# audio_embeddings_val = total_audio_embeddings[len_train:len_train+len_val]\n# audio_embeddings_test = total_audio_embeddings[len_train+len_val:]\n\n\n\n# text_embeddings_train = total_text_embeddings[:len_train]\n# text_embeddings_val = total_text_embeddings[len_train:len_train+len_val]\n# text_embeddings_test = total_text_embeddings[len_train+len_val:]\n\nimage_embeddings_train = total_image_embeddings[:len_train]\nimage_embeddings_val = total_image_embeddings[len_train:len_train+len_val]\nimage_embeddings_test = total_image_embeddings[len_train+len_val:]\n\nwith open('image_dataset_normalized.pkl', 'wb') as f:\n    pickle.dump((image_embeddings_train, image_embeddings_val, image_embeddings_test), f)\n\ndel total_image_embeddings\ndel image_embeddings_train\ndel image_embeddings_val\ndel image_embeddings_test\n    \n# total_dataset_v2 = {\n#     'train': {\n#         'audio': audio_embeddings_train,\n#         'text': text_embeddings_train,\n#         'image': image_embeddings_train,\n#     },\n#     'validation': {\n#         'audio': audio_embeddings_val,\n#         'text': text_embeddings_val,\n#         'image': image_embeddings_val,\n#     },\n#     'test': {\n#         'audio': audio_embeddings_test,\n#         'text': text_embeddings_test,\n#         'image': image_embeddings_test,\n#     }\n# }","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:56:15.983094Z","iopub.execute_input":"2023-07-31T06:56:15.983500Z","iopub.status.idle":"2023-07-31T06:56:34.174709Z","shell.execute_reply.started":"2023-07-31T06:56:15.983469Z","shell.execute_reply":"2023-07-31T06:56:34.173531Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"torch.Size([114117, 1000])\n","output_type":"stream"}]},{"cell_type":"code","source":"len(image_embeddings_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T07:16:33.978749Z","iopub.execute_input":"2023-07-31T07:16:33.979126Z","iopub.status.idle":"2023-07-31T07:16:33.985629Z","shell.execute_reply.started":"2023-07-31T07:16:33.979077Z","shell.execute_reply":"2023-07-31T07:16:33.984701Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"91294"},"metadata":{}}]},{"cell_type":"code","source":"len(image_embeddings_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-07-31T07:17:31.764442Z","iopub.execute_input":"2023-07-31T07:17:31.764894Z","iopub.status.idle":"2023-07-31T07:17:31.775452Z","shell.execute_reply.started":"2023-07-31T07:17:31.764857Z","shell.execute_reply":"2023-07-31T07:17:31.774330Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}]},{"cell_type":"code","source":"with open('image_dataset_normalized.pkl', 'rb') as f:\n    image_embeddings_train, image_embeddings_val, image_embeddings_test = pickle.load(f)\nimage_embeddings_train = [torch.Tensor(i) for i in image_embeddings_train]\nimage_embeddings_val = [torch.Tensor(i) for i in image_embeddings_val]\nimage_embeddings_test = [torch.Tensor(i) for i in image_embeddings_test]\n\ngc.collect()\n\nwith open('text_dataset_normalized.pkl', 'rb') as f:\n    text_embeddings_train, text_embeddings_val, text_embeddings_test = pickle.load(f)\ntext_embeddings_train = [torch.Tensor(i) for i in text_embeddings_train]\ntext_embeddings_val = [torch.Tensor(i) for i in text_embeddings_val]\ntext_embeddings_test = [torch.Tensor(i) for i in text_embeddings_test]\n\ngc.collect()\n    \nwith open('audio_dataset_normalized.pkl', 'rb') as f:\n    audio_embeddings_train, audio_embeddings_val, audio_embeddings_test = pickle.load(f)\naudio_embeddings_train = [torch.Tensor(i) for i in audio_embeddings_train]\naudio_embeddings_val = [torch.Tensor(i) for i in audio_embeddings_val]\naudio_embeddings_test = [torch.Tensor(i) for i in audio_embeddings_test]\n\ngc.collect()\n    \ntotal_dataset_v2 = {\n    'train': {\n        'audio': audio_embeddings_train,\n        'text': text_embeddings_train,\n        'image': image_embeddings_train,\n    },\n    'validation': {\n        'audio': audio_embeddings_val,\n        'text': text_embeddings_val,\n        'image': image_embeddings_val,\n    },\n    'test': {\n        'audio': audio_embeddings_test,\n        'text': text_embeddings_test,\n        'image': image_embeddings_test,\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2023-07-31T07:19:43.794792Z","iopub.execute_input":"2023-07-31T07:19:43.795176Z","iopub.status.idle":"2023-07-31T07:20:58.000080Z","shell.execute_reply.started":"2023-07-31T07:19:43.795142Z","shell.execute_reply":"2023-07-31T07:20:57.999022Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# save the dataset\nwith open('total_dataset_v2.pkl', 'wb') as f:\n    pickle.dump(total_dataset_v2, f)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T07:20:58.003658Z","iopub.execute_input":"2023-07-31T07:20:58.004037Z","iopub.status.idle":"2023-07-31T07:21:26.800815Z","shell.execute_reply.started":"2023-07-31T07:20:58.004000Z","shell.execute_reply":"2023-07-31T07:21:26.799657Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"with open('total_dataset_v2.pkl', 'rb') as f:\n    total_dataset = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:47:22.076480Z","iopub.execute_input":"2023-08-06T15:47:22.077570Z","iopub.status.idle":"2023-08-06T15:47:59.866381Z","shell.execute_reply.started":"2023-08-06T15:47:22.077522Z","shell.execute_reply":"2023-08-06T15:47:59.865003Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"with open('total_dataset_v2_with_text.pkl', 'rb') as f:\n    total_dataset = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:32:28.898153Z","iopub.execute_input":"2023-08-06T15:32:28.898538Z","iopub.status.idle":"2023-08-06T15:32:48.348208Z","shell.execute_reply.started":"2023-08-06T15:32:28.898508Z","shell.execute_reply":"2023-08-06T15:32:48.347126Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"total_dataset['train'].keys()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:47:59.899334Z","iopub.execute_input":"2023-08-06T15:47:59.899704Z","iopub.status.idle":"2023-08-06T15:47:59.921850Z","shell.execute_reply.started":"2023-08-06T15:47:59.899673Z","shell.execute_reply":"2023-08-06T15:47:59.920704Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"dict_keys(['audio', 'text', 'image'])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Prepare dataset","metadata":{}},{"cell_type":"code","source":"class ImageMMDataSet(Dataset):\n    def __init__(self, dataset):\n        self.dataset = dataset\n        \n    def __len__(self):\n        return len(self.dataset['audio'])\n\n    def __getitem__(self, i):\n        return self.dataset['text'][i], self.dataset['audio'][i], self.dataset['image'][i]","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:47:59.923414Z","iopub.execute_input":"2023-08-06T15:47:59.924037Z","iopub.status.idle":"2023-08-06T15:47:59.934442Z","shell.execute_reply.started":"2023-08-06T15:47:59.924000Z","shell.execute_reply":"2023-08-06T15:47:59.933425Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# text_embedding_train, text_embedding_val, audio_embedding_train, audio_embedding_val, image_embedding_train, image_embedding_val = train_test_split(selected_text_embeddings, selected_audio_embeddings, selected_image_embeddings, test_size=0.2, random_state=42)\n# text_embedding_val, text_embedding_test, audio_embedding_val, audio_embedding_test, image_embedding_val, image_embedding_test = train_test_split(text_embedding_val, audio_embedding_val, image_embedding_val, test_size=0.5, random_state=42)\n\ntrain_loader = DataLoader(dataset= ImageMMDataSet(total_dataset['train']), batch_size=32, shuffle=True)\nval_loader = DataLoader(dataset= ImageMMDataSet(total_dataset['validation']), batch_size=16, shuffle=False)\ntest_loader = DataLoader(dataset= ImageMMDataSet(total_dataset['test']), batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:47:59.936688Z","iopub.execute_input":"2023-08-06T15:47:59.937040Z","iopub.status.idle":"2023-08-06T15:48:00.083110Z","shell.execute_reply.started":"2023-08-06T15:47:59.937007Z","shell.execute_reply":"2023-08-06T15:48:00.080989Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"for text, audio, image in train_loader:\n    print(text.shape, audio.shape, image.shape)\n    print(text.requires_grad)\n    print(audio.requires_grad)\n    print(image.requires_grad)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-07-31T21:29:03.898771Z","iopub.execute_input":"2023-07-31T21:29:03.899249Z","iopub.status.idle":"2023-07-31T21:29:03.956653Z","shell.execute_reply.started":"2023-07-31T21:29:03.899211Z","shell.execute_reply":"2023-07-31T21:29:03.955517Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"torch.Size([32, 768]) torch.Size([32, 768]) torch.Size([32, 1000])\nFalse\nFalse\nFalse\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Text-Image model","metadata":{}},{"cell_type":"code","source":"class ImageTextAudioNN(nn.Module):\n    def __init__(self, in_features_text, in_features_image):\n        super(ImageTextAudioNN, self).__init__()\n        self.image_seq = nn.Sequential(\n            nn.Linear(in_features_image, 576),\n            nn.BatchNorm1d(576),\n            nn.LeakyReLU(),\n            nn.Dropout(p=0.15),\n            nn.Linear(576, 384),\n            nn.BatchNorm1d(384),\n            nn.LeakyReLU(),\n            nn.Dropout(p=0.1),\n            nn.Linear(384, 576),\n            nn.LeakyReLU(),\n            nn.Linear(576, in_features_text),\n        )\n        self.audio_seq = nn.Sequential(\n            nn.Linear(in_features_text, 576),\n            nn.BatchNorm1d(576),\n            nn.LeakyReLU(),\n            nn.Dropout(p=0.15),\n            nn.Linear(576, 384),\n            nn.BatchNorm1d(384),\n            nn.LeakyReLU(),\n            nn.Dropout(p=0.1),\n            nn.Linear(384, 576),\n            nn.LeakyReLU(),\n            nn.Linear(576, in_features_text),\n        )\n        \n        self.mix_seq = nn.Sequential(\n            nn.Linear(2 * in_features_text, 1024),\n            nn.BatchNorm1d(1024),\n            nn.LeakyReLU(),\n            nn.Linear(1024, 800),\n            nn.LeakyReLU(),\n            nn.Linear(800, in_features_text),\n        )\n    \n    def forward(self, x_audio, x_image):\n        x1 = self.audio_seq(x_audio)\n        x2 = self.image_seq(x_image)\n        concats = torch.cat((x1, x2), dim=1)\n        x = self.mix_seq(concats)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:33:35.141079Z","iopub.execute_input":"2023-08-06T15:33:35.142216Z","iopub.status.idle":"2023-08-06T15:33:35.155875Z","shell.execute_reply.started":"2023-08-06T15:33:35.142172Z","shell.execute_reply":"2023-08-06T15:33:35.154170Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class TextAudioNN(nn.Module):\n    def __init__(self, in_features_text):\n        super(TextAudioNN, self).__init__()\n        self.audio_seq = nn.Sequential(\n            nn.Linear(in_features_text, 576),\n            nn.BatchNorm1d(576),\n            nn.LeakyReLU(),\n            nn.Dropout(p=0.15),\n            nn.Linear(576, 384),\n            nn.BatchNorm1d(384),\n            nn.LeakyReLU(),\n            nn.Dropout(p=0.1),\n            nn.Linear(384, 576),\n            nn.LeakyReLU(),\n            nn.Linear(576, in_features_text),\n        )\n    \n    def forward(self, x_audio):\n        x1 = self.audio_seq(x_audio)\n        return x1","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:33:35.795369Z","iopub.execute_input":"2023-08-06T15:33:35.795783Z","iopub.status.idle":"2023-08-06T15:33:35.802934Z","shell.execute_reply.started":"2023-08-06T15:33:35.795751Z","shell.execute_reply":"2023-08-06T15:33:35.801890Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class ImagetextNN(nn.Module):\n    def __init__(self, in_features_text, in_features_image):\n        super(ImagetextNN, self).__init__()\n        self.image_seq = nn.Sequential(\n            nn.Linear(in_features_image, 576),\n            nn.BatchNorm1d(576),\n            nn.LeakyReLU(),\n            nn.Dropout(p=0.15),\n            nn.Linear(576, 384),\n            nn.BatchNorm1d(384),\n            nn.LeakyReLU(),\n            nn.Dropout(p=0.1),\n            nn.Linear(384, 576),\n            nn.LeakyReLU(),\n            nn.Linear(576, in_features_text),\n        )\n       \n    def forward(self, x_image):\n        x2 = self.image_seq(x_image)\n        return x2","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:33:36.194948Z","iopub.execute_input":"2023-08-06T15:33:36.195776Z","iopub.status.idle":"2023-08-06T15:33:36.203043Z","shell.execute_reply.started":"2023-08-06T15:33:36.195731Z","shell.execute_reply":"2023-08-06T15:33:36.202092Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def train_the_model(model, train_dataloader, val_dataloader, mode, num_epochs=100, learning_rate=5e-6, delta=0.6):\n    criterion = nn.HuberLoss(delta=delta)\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n\n    def eval_epoch(model: nn.Module, criterion: nn.Module, dataloader: torch.utils.data.DataLoader, test_mode=False, mode='joint'):\n        eval_loss = 0\n        model.eval()\n\n        with torch.no_grad(), tqdm(enumerate(dataloader), total=len(dataloader)) as pbar:\n            for i, (text_emb, audio_emb, image_emb) in pbar:\n                text_emb = text_emb.to(device)\n                if mode == 'joint':\n                    audio_emb = audio_emb.to(device)\n                    image_emb = image_emb.to(device)\n                    final_emb = model(audio_emb, image_emb) \n                elif mode == 'audio':\n                    audio_emb = audio_emb.to(device)\n                    final_emb = model(audio_emb)\n                elif mode == 'image':\n                    image_emb = image_emb.to(device)\n                    final_emb = model(image_emb)              \n\n                loss = criterion(final_emb, text_emb)\n\n                eval_loss += loss.item()\n\n                discription = 'Validation' if not test_mode else 'Test'\n                pbar.set_description(f'{discription} Loss: {loss.item():.4f}')\n        return eval_loss\n    \n    def train_epoch(model: nn.Module, criterion: nn.Module, optimizer: torch.optim.Optimizer, dataloader: torch.utils.data.DataLoader, mode='joint'):\n        train_loss = 0\n        model.train()\n\n        with tqdm(enumerate(dataloader), total=len(dataloader)) as pbar:\n            for i, (text_emb, audio_emb, image_emb) in pbar:\n#                 if not audio_emb.requires_grad:\n#                     audio_emb.requires_grad_(True)\n#                 print(audio_emb.requires_grad)\n#                 if not image_emb.requires_grad:\n#                     image_emb.requires_grad_(True)\n#                 if not text_emb.requires_grad:\n#                     text_emb.requires_grad_(True)\n#                 print(image_emb.requires_grad)\n                    \n                text_emb = text_emb.to(device)\n                if mode == 'joint':\n                    audio_emb = audio_emb.to(device)\n                    image_emb = image_emb.to(device)\n                    final_emb = model(audio_emb, image_emb) \n                elif mode == 'audio':\n                    audio_emb = audio_emb.to(device)\n                    final_emb = model(audio_emb)\n                elif mode == 'image':\n                    image_emb = image_emb.to(device)\n                    final_emb = model(image_emb)              \n\n                loss = criterion(final_emb, text_emb)\n\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n                train_loss += loss.item()\n\n                pbar.set_description(f'Train Loss: {loss.item():.4f}')\n        return train_loss\n    \n    def train(model: nn.Module, criterion: nn.Module, optimizer: torch.optim.Optimizer, train_dataloader: torch.utils.data.DataLoader, val_dataloader: torch.utils.data.DataLoader, epochs: int, mode='joint'):\n        train_losses = []\n        val_losses = []\n        for epoch in range(epochs):\n            gc.collect()\n            torch.cuda.empty_cache()\n            torch.cuda.ipc_collect()\n            start_time = time()\n\n            train_loss = train_epoch(model, criterion, optimizer, train_dataloader, mode)\n            val_loss = eval_epoch(model, criterion, val_dataloader, mode=mode)\n            train_losses.append(train_loss)\n            val_losses.append(val_loss)\n\n            end_time = time()\n            \n            print(f'Epoch {epoch + 1} finished in {end_time - start_time:.2f}s')\n            print(f\"[Epoch {epoch + 1}]\\t\"\n                f\"Train Loss: {train_loss:.6f}\\t\"\n                f\"Validation Loss: {val_loss:.6f}\")\n        return train_losses, val_losses\n    \n    def plot_loss(loss, num_epochs, label):\n        ls_epoch = [_ + 1 for _ in range(num_epochs)]\n        plt.plot(ls_epoch, loss, color='r', label=label)\n        plt.title('Loss plot')\n        plt.ylabel('Loss')\n        plt.xlabel('epoch')\n        plt.legend()\n        plt.show()\n    \n    \n    train_losses, val_losses = train(model, criterion, optimizer, train_dataloader, val_dataloader, num_epochs, mode)\n    plot_loss(train_losses, num_epochs, 'train')\n    plot_loss(val_losses, num_epochs, 'validation')\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:33:38.789295Z","iopub.execute_input":"2023-08-06T15:33:38.789970Z","iopub.status.idle":"2023-08-06T15:33:38.812172Z","shell.execute_reply.started":"2023-08-06T15:33:38.789934Z","shell.execute_reply":"2023-08-06T15:33:38.811168Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"joint_model = ImageTextAudioNN(768, 1000).to(device)\naudio_text_model = TextAudioNN(768).to(device)\nimage_text_model = ImagetextNN(768, 1000).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T21:29:50.224390Z","iopub.execute_input":"2023-07-31T21:29:50.225063Z","iopub.status.idle":"2023-07-31T21:29:50.314875Z","shell.execute_reply.started":"2023-07-31T21:29:50.225022Z","shell.execute_reply":"2023-07-31T21:29:50.313894Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"joint_model = train_the_model(joint_model, train_loader, val_loader, 'joint', num_epochs=150)\ntorch.save(joint_model, 'joint_model_translation.pt')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T21:29:57.103683Z","iopub.execute_input":"2023-07-31T21:29:57.104055Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Train Loss: 0.0006: 100%|██████████| 2853/2853 [00:21<00:00, 131.53it/s]\nValidation Loss: 0.0006: 100%|██████████| 714/714 [00:02<00:00, 288.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 finished in 24.18s\n[Epoch 1]\tTrain Loss: 4.104502\tValidation Loss: 0.446610\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0006: 100%|██████████| 2853/2853 [00:20<00:00, 141.81it/s]\nValidation Loss: 0.0006: 100%|██████████| 714/714 [00:02<00:00, 279.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 finished in 22.68s\n[Epoch 2]\tTrain Loss: 1.641315\tValidation Loss: 0.411437\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0006: 100%|██████████| 2853/2853 [00:20<00:00, 135.89it/s]\nValidation Loss: 0.0006: 100%|██████████| 714/714 [00:02<00:00, 275.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 finished in 23.59s\n[Epoch 3]\tTrain Loss: 1.588817\tValidation Loss: 0.405077\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 138.36it/s]\nValidation Loss: 0.0006: 100%|██████████| 714/714 [00:02<00:00, 291.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 finished in 23.08s\n[Epoch 4]\tTrain Loss: 1.558374\tValidation Loss: 0.394987\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 140.37it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 286.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 finished in 22.83s\n[Epoch 5]\tTrain Loss: 1.536738\tValidation Loss: 0.391316\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 136.42it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 288.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 finished in 23.40s\n[Epoch 6]\tTrain Loss: 1.525055\tValidation Loss: 0.388453\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 140.32it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 291.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 finished in 22.79s\n[Epoch 7]\tTrain Loss: 1.515883\tValidation Loss: 0.386571\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 137.60it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 274.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 finished in 23.34s\n[Epoch 8]\tTrain Loss: 1.508774\tValidation Loss: 0.384447\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 137.28it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 281.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 finished in 23.33s\n[Epoch 9]\tTrain Loss: 1.502473\tValidation Loss: 0.382587\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 142.81it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 281.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 finished in 22.52s\n[Epoch 10]\tTrain Loss: 1.496492\tValidation Loss: 0.380989\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:22<00:00, 128.90it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 291.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 finished in 24.59s\n[Epoch 11]\tTrain Loss: 1.491147\tValidation Loss: 0.379534\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 139.99it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 290.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 finished in 22.85s\n[Epoch 12]\tTrain Loss: 1.485691\tValidation Loss: 0.378070\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 143.39it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:03<00:00, 228.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 finished in 23.03s\n[Epoch 13]\tTrain Loss: 1.480495\tValidation Loss: 0.376799\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 137.42it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 287.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 finished in 23.25s\n[Epoch 14]\tTrain Loss: 1.475546\tValidation Loss: 0.375473\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 140.26it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 292.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 finished in 22.79s\n[Epoch 15]\tTrain Loss: 1.470867\tValidation Loss: 0.374296\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 134.05it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 279.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 finished in 23.85s\n[Epoch 16]\tTrain Loss: 1.466608\tValidation Loss: 0.373101\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 143.50it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 278.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 finished in 22.46s\n[Epoch 17]\tTrain Loss: 1.462450\tValidation Loss: 0.372293\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 143.13it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 290.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 finished in 22.40s\n[Epoch 18]\tTrain Loss: 1.458718\tValidation Loss: 0.371174\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 133.16it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 289.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19 finished in 23.90s\n[Epoch 19]\tTrain Loss: 1.455069\tValidation Loss: 0.370362\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 140.36it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 289.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20 finished in 22.80s\n[Epoch 20]\tTrain Loss: 1.451571\tValidation Loss: 0.369536\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 137.51it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 274.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21 finished in 23.36s\n[Epoch 21]\tTrain Loss: 1.448406\tValidation Loss: 0.368734\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 138.07it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 288.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22 finished in 23.14s\n[Epoch 22]\tTrain Loss: 1.445422\tValidation Loss: 0.367914\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 139.56it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 287.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23 finished in 22.94s\n[Epoch 23]\tTrain Loss: 1.442489\tValidation Loss: 0.367198\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 134.01it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 282.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24 finished in 23.83s\n[Epoch 24]\tTrain Loss: 1.439711\tValidation Loss: 0.366580\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 143.98it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 286.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25 finished in 22.32s\n[Epoch 25]\tTrain Loss: 1.437134\tValidation Loss: 0.365850\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 137.05it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 277.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26 finished in 23.40s\n[Epoch 26]\tTrain Loss: 1.434525\tValidation Loss: 0.365192\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 137.26it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 289.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27 finished in 23.26s\n[Epoch 27]\tTrain Loss: 1.432011\tValidation Loss: 0.364724\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 140.99it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 270.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28 finished in 22.89s\n[Epoch 28]\tTrain Loss: 1.429727\tValidation Loss: 0.363985\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 135.21it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 282.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29 finished in 23.64s\n[Epoch 29]\tTrain Loss: 1.427533\tValidation Loss: 0.363653\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 139.49it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 286.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30 finished in 22.96s\n[Epoch 30]\tTrain Loss: 1.425395\tValidation Loss: 0.362866\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 138.82it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 281.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31 finished in 23.10s\n[Epoch 31]\tTrain Loss: 1.423251\tValidation Loss: 0.362590\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 138.46it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 245.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32 finished in 23.52s\n[Epoch 32]\tTrain Loss: 1.421308\tValidation Loss: 0.362152\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 143.26it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 280.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33 finished in 22.47s\n[Epoch 33]\tTrain Loss: 1.419232\tValidation Loss: 0.361701\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 134.01it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 276.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34 finished in 23.88s\n[Epoch 34]\tTrain Loss: 1.417529\tValidation Loss: 0.361205\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 139.83it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 288.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35 finished in 22.89s\n[Epoch 35]\tTrain Loss: 1.415715\tValidation Loss: 0.360768\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 142.34it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 269.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36 finished in 22.71s\n[Epoch 36]\tTrain Loss: 1.413846\tValidation Loss: 0.360291\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 136.95it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 296.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37 finished in 23.25s\n[Epoch 37]\tTrain Loss: 1.412166\tValidation Loss: 0.359983\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 141.42it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 292.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38 finished in 22.62s\n[Epoch 38]\tTrain Loss: 1.410569\tValidation Loss: 0.359561\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 134.35it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 276.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39 finished in 23.83s\n[Epoch 39]\tTrain Loss: 1.408973\tValidation Loss: 0.359420\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 142.63it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 285.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40 finished in 22.51s\n[Epoch 40]\tTrain Loss: 1.407344\tValidation Loss: 0.359108\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 140.48it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 293.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41 finished in 22.75s\n[Epoch 41]\tTrain Loss: 1.405823\tValidation Loss: 0.358396\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 134.53it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 280.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42 finished in 23.76s\n[Epoch 42]\tTrain Loss: 1.404209\tValidation Loss: 0.358363\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 141.02it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 288.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43 finished in 22.72s\n[Epoch 43]\tTrain Loss: 1.402857\tValidation Loss: 0.358001\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 138.46it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 276.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44 finished in 23.20s\n[Epoch 44]\tTrain Loss: 1.401115\tValidation Loss: 0.357563\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 138.40it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 288.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45 finished in 23.10s\n[Epoch 45]\tTrain Loss: 1.399978\tValidation Loss: 0.357286\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 140.46it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 285.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46 finished in 22.82s\n[Epoch 46]\tTrain Loss: 1.398658\tValidation Loss: 0.357043\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 135.45it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 248.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47 finished in 23.96s\n[Epoch 47]\tTrain Loss: 1.397125\tValidation Loss: 0.356612\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 142.70it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 287.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48 finished in 22.49s\n[Epoch 48]\tTrain Loss: 1.395852\tValidation Loss: 0.356307\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 137.03it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 281.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49 finished in 23.37s\n[Epoch 49]\tTrain Loss: 1.394307\tValidation Loss: 0.356074\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 138.21it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 288.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 50 finished in 23.13s\n[Epoch 50]\tTrain Loss: 1.393247\tValidation Loss: 0.355945\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 143.15it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 272.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 51 finished in 22.56s\n[Epoch 51]\tTrain Loss: 1.391902\tValidation Loss: 0.355541\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 135.83it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 282.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 52 finished in 23.54s\n[Epoch 52]\tTrain Loss: 1.390565\tValidation Loss: 0.355219\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 139.20it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 285.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 53 finished in 23.00s\n[Epoch 53]\tTrain Loss: 1.389437\tValidation Loss: 0.355074\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 137.34it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 281.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 54 finished in 23.32s\n[Epoch 54]\tTrain Loss: 1.388089\tValidation Loss: 0.355123\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 139.14it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 295.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 55 finished in 22.93s\n[Epoch 55]\tTrain Loss: 1.387173\tValidation Loss: 0.354408\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 138.68it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 283.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 56 finished in 23.10s\n[Epoch 56]\tTrain Loss: 1.385754\tValidation Loss: 0.354226\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 133.38it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 292.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 57 finished in 23.84s\n[Epoch 57]\tTrain Loss: 1.384665\tValidation Loss: 0.354018\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 140.11it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 293.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 58 finished in 22.80s\n[Epoch 58]\tTrain Loss: 1.383499\tValidation Loss: 0.353823\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 141.96it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 276.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 59 finished in 22.69s\n[Epoch 59]\tTrain Loss: 1.382399\tValidation Loss: 0.353601\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 134.07it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 287.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 60 finished in 23.78s\n[Epoch 60]\tTrain Loss: 1.381144\tValidation Loss: 0.353392\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 139.51it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 286.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 61 finished in 22.95s\n[Epoch 61]\tTrain Loss: 1.380198\tValidation Loss: 0.353276\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 134.56it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 275.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 62 finished in 23.81s\n[Epoch 62]\tTrain Loss: 1.379330\tValidation Loss: 0.352949\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 143.17it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 290.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 63 finished in 22.39s\n[Epoch 63]\tTrain Loss: 1.378203\tValidation Loss: 0.352922\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 139.96it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 279.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 64 finished in 22.95s\n[Epoch 64]\tTrain Loss: 1.376910\tValidation Loss: 0.352559\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 133.42it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 288.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 65 finished in 23.87s\n[Epoch 65]\tTrain Loss: 1.375989\tValidation Loss: 0.352442\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 143.28it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 244.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 66 finished in 22.85s\n[Epoch 66]\tTrain Loss: 1.374891\tValidation Loss: 0.352135\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 138.95it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 272.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 67 finished in 23.16s\n[Epoch 67]\tTrain Loss: 1.373772\tValidation Loss: 0.351989\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 139.26it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 287.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 68 finished in 22.98s\n[Epoch 68]\tTrain Loss: 1.372941\tValidation Loss: 0.351685\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 140.02it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 292.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 69 finished in 22.83s\n[Epoch 69]\tTrain Loss: 1.371993\tValidation Loss: 0.351539\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 135.12it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 240.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 70 finished in 24.09s\n[Epoch 70]\tTrain Loss: 1.371044\tValidation Loss: 0.351384\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 142.84it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 292.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 71 finished in 22.43s\n[Epoch 71]\tTrain Loss: 1.369946\tValidation Loss: 0.351275\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 138.01it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 281.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 72 finished in 23.22s\n[Epoch 72]\tTrain Loss: 1.369056\tValidation Loss: 0.351026\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 138.12it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 281.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 73 finished in 23.20s\n[Epoch 73]\tTrain Loss: 1.367866\tValidation Loss: 0.350881\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 142.25it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 293.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 74 finished in 22.50s\n[Epoch 74]\tTrain Loss: 1.367117\tValidation Loss: 0.350634\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 131.99it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 292.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 75 finished in 24.07s\n[Epoch 75]\tTrain Loss: 1.366276\tValidation Loss: 0.350609\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 141.02it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 287.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 76 finished in 22.72s\n[Epoch 76]\tTrain Loss: 1.365162\tValidation Loss: 0.350350\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 138.55it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 284.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 77 finished in 23.11s\n[Epoch 77]\tTrain Loss: 1.364163\tValidation Loss: 0.350247\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 139.31it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 293.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 78 finished in 22.92s\n[Epoch 78]\tTrain Loss: 1.363628\tValidation Loss: 0.350115\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 140.15it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 282.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 79 finished in 22.89s\n[Epoch 79]\tTrain Loss: 1.362507\tValidation Loss: 0.349860\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 133.05it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 290.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 80 finished in 23.91s\n[Epoch 80]\tTrain Loss: 1.361448\tValidation Loss: 0.349762\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 141.21it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 268.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 81 finished in 22.87s\n[Epoch 81]\tTrain Loss: 1.360685\tValidation Loss: 0.349594\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 142.98it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 273.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 82 finished in 22.57s\n[Epoch 82]\tTrain Loss: 1.359844\tValidation Loss: 0.349478\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 134.57it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 291.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 83 finished in 23.66s\n[Epoch 83]\tTrain Loss: 1.358979\tValidation Loss: 0.349298\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 139.85it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 292.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 84 finished in 22.85s\n[Epoch 84]\tTrain Loss: 1.358397\tValidation Loss: 0.349170\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 136.94it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:03<00:00, 226.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 85 finished in 24.00s\n[Epoch 85]\tTrain Loss: 1.357461\tValidation Loss: 0.349158\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 142.75it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 288.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 86 finished in 22.47s\n[Epoch 86]\tTrain Loss: 1.356449\tValidation Loss: 0.349039\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 138.14it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 292.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 87 finished in 23.10s\n[Epoch 87]\tTrain Loss: 1.355668\tValidation Loss: 0.348803\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:21<00:00, 132.94it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 296.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 88 finished in 23.88s\n[Epoch 88]\tTrain Loss: 1.354994\tValidation Loss: 0.348692\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 142.79it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 269.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 89 finished in 22.64s\n[Epoch 89]\tTrain Loss: 1.353941\tValidation Loss: 0.348449\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 139.63it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 290.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 91 finished in 22.90s\n[Epoch 91]\tTrain Loss: 1.352497\tValidation Loss: 0.348347\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 139.63it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 292.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 94 finished in 22.88s\n[Epoch 94]\tTrain Loss: 1.350177\tValidation Loss: 0.348239\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 137.08it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 276.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 95 finished in 23.40s\n[Epoch 95]\tTrain Loss: 1.349320\tValidation Loss: 0.347748\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005:  53%|█████▎    | 1502/2853 [00:10<00:09, 144.89it/s]","output_type":"stream"}]},{"cell_type":"code","source":"joint_model = torch.load('joint_model_translation.pt')\njoint_model = train_the_model(joint_model, train_loader, val_loader, 'joint', num_epochs=100, learning_rate=1e-6)\ntorch.save(joint_model, 'joint_model_translation_v2.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joint_model = train_the_model(joint_model, train_loader, val_loader, 'joint', num_epochs=150)\ntorch.save(joint_model, 'joint_model_v2.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio_text_model = train_the_model(audio_text_model, train_loader, val_loader, 'audio')\ntorch.save(audio_text_model, 'audio_text_model.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_text_model = train_the_model(image_text_model, train_loader, val_loader, 'image')\ntorch.save(image_text_model, 'image_text_model.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joint_model = torch.load('joint_model_v2.pt')\njoint_model = train_the_model(joint_model, train_loader, val_loader, 'joint', num_epochs=100, learning_rate=1e-6)\ntorch.save(joint_model, 'joint_model_v3.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joint_model = train_the_model(joint_model, train_loader, val_loader, 'joint', num_epochs=50)\ntorch.save(joint_model, 'joint_model_50epochs_v2.pt')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T07:25:02.629696Z","iopub.execute_input":"2023-07-31T07:25:02.630053Z","iopub.status.idle":"2023-07-31T07:44:00.298444Z","shell.execute_reply.started":"2023-07-31T07:25:02.630022Z","shell.execute_reply":"2023-07-31T07:44:00.297425Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Train Loss: 0.0006: 100%|██████████| 2853/2853 [00:21<00:00, 134.05it/s]\nValidation Loss: 0.0006: 100%|██████████| 714/714 [00:02<00:00, 302.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 finished in 23.66s\n[Epoch 1]\tTrain Loss: 4.171553\tValidation Loss: 0.446469\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0006: 100%|██████████| 2853/2853 [00:19<00:00, 144.96it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 267.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 finished in 22.36s\n[Epoch 2]\tTrain Loss: 1.644391\tValidation Loss: 0.411503\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 145.73it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 292.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 finished in 22.03s\n[Epoch 3]\tTrain Loss: 1.591634\tValidation Loss: 0.405639\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 141.81it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 294.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 finished in 22.55s\n[Epoch 4]\tTrain Loss: 1.560832\tValidation Loss: 0.395614\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 142.44it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 288.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 finished in 22.51s\n[Epoch 5]\tTrain Loss: 1.538940\tValidation Loss: 0.391650\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 145.66it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 290.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 finished in 22.06s\n[Epoch 6]\tTrain Loss: 1.527591\tValidation Loss: 0.388962\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 145.04it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 303.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 finished in 22.03s\n[Epoch 7]\tTrain Loss: 1.518769\tValidation Loss: 0.387143\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 146.45it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 298.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 finished in 21.88s\n[Epoch 8]\tTrain Loss: 1.511829\tValidation Loss: 0.385137\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 150.08it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 310.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 finished in 21.32s\n[Epoch 9]\tTrain Loss: 1.506035\tValidation Loss: 0.383762\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 145.60it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 298.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 finished in 22.00s\n[Epoch 10]\tTrain Loss: 1.500713\tValidation Loss: 0.382310\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 145.29it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 305.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 finished in 21.98s\n[Epoch 11]\tTrain Loss: 1.495376\tValidation Loss: 0.380710\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 147.52it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 264.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 finished in 22.05s\n[Epoch 12]\tTrain Loss: 1.490214\tValidation Loss: 0.379147\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 148.38it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 303.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 finished in 21.59s\n[Epoch 13]\tTrain Loss: 1.485203\tValidation Loss: 0.377834\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:20<00:00, 137.41it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 306.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 finished in 23.10s\n[Epoch 14]\tTrain Loss: 1.480269\tValidation Loss: 0.376496\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 145.25it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 298.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 finished in 22.05s\n[Epoch 15]\tTrain Loss: 1.475686\tValidation Loss: 0.375196\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 144.09it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 289.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 finished in 22.27s\n[Epoch 16]\tTrain Loss: 1.471368\tValidation Loss: 0.374071\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 144.53it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 291.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 finished in 22.20s\n[Epoch 17]\tTrain Loss: 1.467232\tValidation Loss: 0.373217\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 145.21it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 295.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 finished in 22.07s\n[Epoch 18]\tTrain Loss: 1.463179\tValidation Loss: 0.372087\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 145.26it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 287.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19 finished in 22.14s\n[Epoch 19]\tTrain Loss: 1.459467\tValidation Loss: 0.371157\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 148.85it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:02<00:00, 298.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20 finished in 21.57s\n[Epoch 20]\tTrain Loss: 1.456158\tValidation Loss: 0.370530\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 149.99it/s]\nValidation Loss: 0.0004: 100%|██████████| 714/714 [00:02<00:00, 333.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30 finished in 21.17s\n[Epoch 30]\tTrain Loss: 1.429047\tValidation Loss: 0.363783\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005:  28%|██▊       | 802/2853 [00:05<00:15, 129.93it/s]IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\nValidation Loss: 0.0004: 100%|██████████| 714/714 [00:02<00:00, 331.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31 finished in 20.86s\n[Epoch 31]\tTrain Loss: 1.426965\tValidation Loss: 0.363395\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005:  82%|████████▏ | 2329/2853 [00:15<00:04, 120.64it/s]IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\nTrain Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 145.91it/s]\nValidation Loss: 0.0004: 100%|██████████| 714/714 [00:02<00:00, 306.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38 finished in 21.90s\n[Epoch 38]\tTrain Loss: 1.413544\tValidation Loss: 0.360106\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 145.97it/s]\nValidation Loss: 0.0004: 100%|██████████| 714/714 [00:02<00:00, 300.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39 finished in 21.94s\n[Epoch 39]\tTrain Loss: 1.411903\tValidation Loss: 0.359873\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 149.89it/s]\nValidation Loss: 0.0004: 100%|██████████| 714/714 [00:02<00:00, 303.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40 finished in 21.40s\n[Epoch 40]\tTrain Loss: 1.410323\tValidation Loss: 0.359414\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 145.91it/s]\nValidation Loss: 0.0004: 100%|██████████| 714/714 [00:02<00:00, 306.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41 finished in 21.89s\n[Epoch 41]\tTrain Loss: 1.408579\tValidation Loss: 0.359188\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 142.78it/s]\nValidation Loss: 0.0004: 100%|██████████| 714/714 [00:02<00:00, 299.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42 finished in 22.37s\n[Epoch 42]\tTrain Loss: 1.407065\tValidation Loss: 0.358675\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:18<00:00, 150.28it/s]\nValidation Loss: 0.0004: 100%|██████████| 714/714 [00:02<00:00, 290.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43 finished in 21.45s\n[Epoch 43]\tTrain Loss: 1.405789\tValidation Loss: 0.358353\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 149.38it/s]\nValidation Loss: 0.0004: 100%|██████████| 714/714 [00:02<00:00, 300.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44 finished in 21.49s\n[Epoch 44]\tTrain Loss: 1.404060\tValidation Loss: 0.358063\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 145.26it/s]\nValidation Loss: 0.0004: 100%|██████████| 714/714 [00:02<00:00, 299.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45 finished in 22.04s\n[Epoch 45]\tTrain Loss: 1.402589\tValidation Loss: 0.357757\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 146.68it/s]\nValidation Loss: 0.0004: 100%|██████████| 714/714 [00:02<00:00, 302.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46 finished in 21.82s\n[Epoch 46]\tTrain Loss: 1.401456\tValidation Loss: 0.357575\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 147.74it/s]\nValidation Loss: 0.0004: 100%|██████████| 714/714 [00:02<00:00, 300.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47 finished in 21.70s\n[Epoch 47]\tTrain Loss: 1.399999\tValidation Loss: 0.357184\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 144.85it/s]\nValidation Loss: 0.0004: 100%|██████████| 714/714 [00:02<00:00, 306.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48 finished in 22.04s\n[Epoch 48]\tTrain Loss: 1.398520\tValidation Loss: 0.356972\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 145.80it/s]\nValidation Loss: 0.0004: 100%|██████████| 714/714 [00:02<00:00, 308.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49 finished in 21.89s\n[Epoch 49]\tTrain Loss: 1.397543\tValidation Loss: 0.356675\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:19<00:00, 148.81it/s]\nValidation Loss: 0.0004: 100%|██████████| 714/714 [00:02<00:00, 298.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 50 finished in 21.57s\n[Epoch 50]\tTrain Loss: 1.395990\tValidation Loss: 0.356394\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"audio_text_model = train_the_model(audio_text_model, train_loader, val_loader, 'audio', num_epochs=50)\ntorch.save(audio_text_model, 'audio_text_model_50epochs_v2.pt')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T07:44:00.300579Z","iopub.execute_input":"2023-07-31T07:44:00.301027Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Train Loss: 0.0008: 100%|██████████| 2853/2853 [00:12<00:00, 223.93it/s]\nValidation Loss: 0.0008: 100%|██████████| 714/714 [00:01<00:00, 428.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 finished in 14.42s\n[Epoch 1]\tTrain Loss: 7.654460\tValidation Loss: 0.567703\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0006: 100%|██████████| 2853/2853 [00:12<00:00, 233.48it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 434.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 finished in 13.87s\n[Epoch 2]\tTrain Loss: 1.990477\tValidation Loss: 0.423231\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0006: 100%|██████████| 2853/2853 [00:12<00:00, 223.18it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 439.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 finished in 14.42s\n[Epoch 3]\tTrain Loss: 1.636083\tValidation Loss: 0.410533\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0006: 100%|██████████| 2853/2853 [00:12<00:00, 230.37it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 401.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 finished in 14.18s\n[Epoch 4]\tTrain Loss: 1.598435\tValidation Loss: 0.405730\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0006: 100%|██████████| 2853/2853 [00:12<00:00, 222.65it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 443.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 finished in 14.43s\n[Epoch 5]\tTrain Loss: 1.574802\tValidation Loss: 0.399064\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:12<00:00, 229.49it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 407.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 finished in 14.19s\n[Epoch 6]\tTrain Loss: 1.555893\tValidation Loss: 0.396019\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0006: 100%|██████████| 2853/2853 [00:12<00:00, 224.55it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 433.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 finished in 14.36s\n[Epoch 7]\tTrain Loss: 1.546710\tValidation Loss: 0.393875\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:12<00:00, 234.33it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 413.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 finished in 13.91s\n[Epoch 8]\tTrain Loss: 1.539767\tValidation Loss: 0.391898\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:12<00:00, 222.49it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 422.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 finished in 14.52s\n[Epoch 9]\tTrain Loss: 1.533425\tValidation Loss: 0.390601\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:12<00:00, 231.64it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 415.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 finished in 14.04s\n[Epoch 10]\tTrain Loss: 1.528065\tValidation Loss: 0.389028\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:12<00:00, 224.73it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 412.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 finished in 14.44s\n[Epoch 11]\tTrain Loss: 1.523371\tValidation Loss: 0.388021\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:12<00:00, 231.87it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 417.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 finished in 14.02s\n[Epoch 12]\tTrain Loss: 1.519406\tValidation Loss: 0.386998\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:12<00:00, 226.10it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 397.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 finished in 14.43s\n[Epoch 13]\tTrain Loss: 1.515333\tValidation Loss: 0.386169\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:12<00:00, 230.77it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 410.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 finished in 14.11s\n[Epoch 14]\tTrain Loss: 1.511938\tValidation Loss: 0.385223\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:12<00:00, 233.06it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 367.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 finished in 14.20s\n[Epoch 15]\tTrain Loss: 1.508287\tValidation Loss: 0.384273\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:12<00:00, 228.30it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 404.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 finished in 14.27s\n[Epoch 16]\tTrain Loss: 1.504622\tValidation Loss: 0.383572\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:12<00:00, 232.42it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 433.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 finished in 13.93s\n[Epoch 17]\tTrain Loss: 1.501563\tValidation Loss: 0.382609\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:12<00:00, 223.73it/s]\nValidation Loss: 0.0005: 100%|██████████| 714/714 [00:01<00:00, 411.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 finished in 14.50s\n[Epoch 18]\tTrain Loss: 1.498245\tValidation Loss: 0.381638\n","output_type":"stream"},{"name":"stderr","text":"Train Loss: 0.0005: 100%|██████████| 2853/2853 [00:12<00:00, 230.57it/s]\nValidation Loss: 0.0005:  70%|██████▉   | 497/714 [00:01<00:00, 439.24it/s]","output_type":"stream"}]},{"cell_type":"code","source":"image_text_model = train_the_model(image_text_model, train_loader, val_loader, 'image', num_epochs=50)\ntorch.save(image_text_model, 'image_text_model_50epochs_v2.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"test_len_data = len(total_dataset['test']['text'])\n\nnumber_of_candidates_per_sample = 5\ntest_metadata = []\n\nfor index in range(test_len_data):\n    candidate_indexes = random.sample([i for i in range(test_len_data) if i != index], number_of_candidates_per_sample - 1)\n    candidate_indexes += [index]\n    test_metadata.append(candidate_indexes)\nlen(test_metadata)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:54:36.610578Z","iopub.execute_input":"2023-08-06T15:54:36.611101Z","iopub.status.idle":"2023-08-06T15:54:50.832289Z","shell.execute_reply.started":"2023-08-06T15:54:36.611060Z","shell.execute_reply":"2023-08-06T15:54:50.831277Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"11411"},"metadata":{}}]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, test_dataset, metadata):\n        self.data = test_dataset\n        self.metadata = metadata\n\n    def __len__(self):\n        return len(self.metadata)\n\n    def __getitem__(self, index):\n        candidate_indexes = self.metadata[index]\n        text_embedding = self.data['text'][index]\n        audio_embeddings = [self.data['audio'][i] for i in candidate_indexes]\n        image_embeddings = [self.data['image'][i] for i in candidate_indexes]\n        label_index = len(candidate_indexes) - 1\n        audio_embeddings = torch.stack(audio_embeddings)\n        image_embeddings = torch.stack(image_embeddings)\n\n        return text_embedding, audio_embeddings, image_embeddings, label_index","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:54:50.837072Z","iopub.execute_input":"2023-08-06T15:54:50.839298Z","iopub.status.idle":"2023-08-06T15:54:50.849970Z","shell.execute_reply.started":"2023-08-06T15:54:50.839261Z","shell.execute_reply":"2023-08-06T15:54:50.849092Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(total_dataset['test'], test_metadata)\ntest_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:54:50.854101Z","iopub.execute_input":"2023-08-06T15:54:50.856425Z","iopub.status.idle":"2023-08-06T15:54:50.875669Z","shell.execute_reply.started":"2023-08-06T15:54:50.856390Z","shell.execute_reply":"2023-08-06T15:54:50.874705Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def evaluate(model_path, mode='joint', threshold=0.5):\n    model = torch.load(model_path)\n    model.eval()\n    model = model.to(device)\n\n    def compute_cosine_similarity(embedding1: torch.Tensor, embedding2: torch.Tensor) -> float:\n        similarity = cosine_similarity(embedding1.unsqueeze(0), embedding2.unsqueeze(0)).item()\n        return similarity\n\n    def cosine_similarity(embedding1, embedding2):\n        dim = 1\n        embedding1 = F.normalize(embedding1, p=2, dim=dim)\n        embedding2 = F.normalize(embedding2, p=2, dim=dim)\n\n        dot_product = torch.sum(embedding1 * embedding2, dim=dim)\n\n        magnitude1 = torch.norm(embedding1, p=2, dim=dim)\n        magnitude2 = torch.norm(embedding2, p=2, dim=dim)\n\n        cosine_sim = dot_product / (magnitude1 * magnitude2)\n\n        return cosine_sim\n    \n    def _evaluate(model, dataloader, threshold=0.5, mode='joint'):\n        total_hits_1 = 0\n        total_mrr = 0\n        total_instances = 0\n        total_labels = []\n        total_predictions = []\n        number_of_golden_predictions = 0\n\n        with torch.no_grad():\n            for text_embedding, audio_candidates, image_candidates, label in tqdm(dataloader):\n                label = label[0]\n                text_embedding = text_embedding[0].to(device)\n                label = label.to(device)\n\n                if mode == 'joint':   \n                    audio_candidates = audio_candidates[0]\n                    audio_candidates = audio_candidates.to(device)\n                    \n                    image_candidates = image_candidates[0]\n                    image_candidates = image_candidates.to(device)\n                    final_embs = model(audio_candidates, image_candidates)\n                elif mode == 'audio':\n                    audio_candidates = audio_candidates[0]\n                    audio_candidates = audio_candidates.to(device)\n                    final_embs = model(audio_candidates)\n                elif mode == 'image':\n                    image_candidates = image_candidates[0]\n                    image_candidates = image_candidates.to(device)\n                    final_embs = model(image_candidates)    \n                \n                text_candidate_cosine_similarities = [compute_cosine_similarity(text_embedding, item) for item in final_embs]\n                predicted_idx = np.argmax(text_candidate_cosine_similarities)\n                \n                label_similarity = text_candidate_cosine_similarities[label.item()]\n\n                # Compute Hits@1\n                if predicted_idx == label.item():   \n                    total_hits_1 += 1\n\n                # Compute MRR\n                label_rank = sum([1 for x in text_candidate_cosine_similarities if x > text_candidate_cosine_similarities[label.item()]])\n                reciprocal_rank = 1 / (label_rank + 1)\n                total_mrr += reciprocal_rank\n\n                # Record predictions and labels\n                predictions = [0 if sim < threshold else 1 for sim in text_candidate_cosine_similarities]\n                total_labels.extend([0 if i != label.item() else 1 for i in range(len(text_candidate_cosine_similarities))])\n                total_predictions.extend(predictions)\n                if label_similarity >= threshold:\n                    number_of_golden_predictions += 1\n\n                total_instances += 1\n\n        # Compute average metrics over all instances\n        avg_hits_1 = total_hits_1 / total_instances\n        avg_mrr = total_mrr / total_instances\n        precision = precision_score(total_labels, total_predictions, average='macro')\n        recall = recall_score(total_labels, total_predictions, average='macro')\n        f1 = f1_score(total_labels, total_predictions, average='macro')\n        precision_micro = precision_score(total_labels, total_predictions, average='micro')\n        recall_micro = recall_score(total_labels, total_predictions, average='micro')\n        f1_micro = f1_score(total_labels, total_predictions, average='micro')\n        accuracy = accuracy_score(total_labels, total_predictions)\n        golden_prediction_accuracy = number_of_golden_predictions / total_instances\n\n        return {\n            'Hits@1': avg_hits_1,\n            'MRR': avg_mrr,\n            'Macro Precision': precision,\n            'Macro Recall': recall,\n            'Macro F1': f1,\n            'Micro Precision': precision_micro,\n            'Micro Recall': recall_micro,\n            'Micro F1': f1_micro,\n            'Accuracy': accuracy,\n            'Golden Accuracy': golden_prediction_accuracy,\n        }\n    \n    results = _evaluate(model, test_final_loader, threshold=threshold, mode=mode)\n    table = []\n    for i in range(len(results)):\n        table.append([list(results.keys())[i], list(results.values())[i]])\n    print(tabulate(table, ['Metrics', 'Values'], tablefmt=\"grid\"))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:54:50.881837Z","iopub.execute_input":"2023-08-06T15:54:50.882200Z","iopub.status.idle":"2023-08-06T15:54:50.918054Z","shell.execute_reply.started":"2023-08-06T15:54:50.882163Z","shell.execute_reply":"2023-08-06T15:54:50.916959Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# 5 candidates\nevaluate('joint_model_translation.pt', mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:54:50.922586Z","iopub.execute_input":"2023-08-06T15:54:50.925035Z","iopub.status.idle":"2023-08-06T15:55:20.383326Z","shell.execute_reply.started":"2023-08-06T15:54:50.925000Z","shell.execute_reply":"2023-08-06T15:55:20.382319Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:28<00:00, 396.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.980195 |\n+-----------------+----------+\n| MRR             | 0.989745 |\n+-----------------+----------+\n| Macro Precision | 0.885158 |\n+-----------------+----------+\n| Macro Recall    | 0.90703  |\n+-----------------+----------+\n| Macro F1        | 0.895463 |\n+-----------------+----------+\n| Micro Precision | 0.931172 |\n+-----------------+----------+\n| Micro Recall    | 0.931172 |\n+-----------------+----------+\n| Micro F1        | 0.931172 |\n+-----------------+----------+\n| Accuracy        | 0.931172 |\n+-----------------+----------+\n| Golden Accuracy | 0.866795 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"# 5 candidates\nevaluate('joint_model_translation_v2.pt', mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:37:27.781707Z","iopub.execute_input":"2023-08-06T15:37:27.782394Z","iopub.status.idle":"2023-08-06T15:37:58.109909Z","shell.execute_reply.started":"2023-08-06T15:37:27.782358Z","shell.execute_reply":"2023-08-06T15:37:58.108828Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:29<00:00, 385.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.980983 |\n+-----------------+----------+\n| MRR             | 0.990115 |\n+-----------------+----------+\n| Macro Precision | 0.891825 |\n+-----------------+----------+\n| Macro Recall    | 0.910569 |\n+-----------------+----------+\n| Macro F1        | 0.900744 |\n+-----------------+----------+\n| Micro Precision | 0.93494  |\n+-----------------+----------+\n| Micro Recall    | 0.93494  |\n+-----------------+----------+\n| Micro F1        | 0.93494  |\n+-----------------+----------+\n| Accuracy        | 0.93494  |\n+-----------------+----------+\n| Golden Accuracy | 0.86995  |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"# 10 candidates\nevaluate('joint_model_translation.pt', mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:42:54.742612Z","iopub.execute_input":"2023-08-06T15:42:54.743291Z","iopub.status.idle":"2023-08-06T15:43:41.178242Z","shell.execute_reply.started":"2023-08-06T15:42:54.743255Z","shell.execute_reply":"2023-08-06T15:43:41.177190Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:45<00:00, 253.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.96109  |\n+-----------------+----------+\n| MRR             | 0.979341 |\n+-----------------+----------+\n| Macro Precision | 0.815586 |\n+-----------------+----------+\n| Macro Recall    | 0.907073 |\n+-----------------+----------+\n| Macro F1        | 0.853137 |\n+-----------------+----------+\n| Micro Precision | 0.939295 |\n+-----------------+----------+\n| Micro Recall    | 0.939295 |\n+-----------------+----------+\n| Micro F1        | 0.939295 |\n+-----------------+----------+\n| Accuracy        | 0.939295 |\n+-----------------+----------+\n| Golden Accuracy | 0.866795 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"# 10 candidates\nevaluate('joint_model_translation_v2.pt', mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:43:41.180367Z","iopub.execute_input":"2023-08-06T15:43:41.180766Z","iopub.status.idle":"2023-08-06T15:44:26.288273Z","shell.execute_reply.started":"2023-08-06T15:43:41.180730Z","shell.execute_reply":"2023-08-06T15:44:26.287135Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:43<00:00, 260.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.963807 |\n+-----------------+----------+\n| MRR             | 0.98051  |\n+-----------------+----------+\n| Macro Precision | 0.820517 |\n+-----------------+----------+\n| Macro Recall    | 0.909634 |\n+-----------------+----------+\n| Macro F1        | 0.857413 |\n+-----------------+----------+\n| Micro Precision | 0.941381 |\n+-----------------+----------+\n| Micro Recall    | 0.941381 |\n+-----------------+----------+\n| Micro F1        | 0.941381 |\n+-----------------+----------+\n| Accuracy        | 0.941381 |\n+-----------------+----------+\n| Golden Accuracy | 0.86995  |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('joint_model_v3.pt', mode='joint')","metadata":{"execution":{"iopub.status.busy":"2023-07-30T22:50:36.450254Z","iopub.execute_input":"2023-07-30T22:50:36.450955Z","iopub.status.idle":"2023-07-30T22:51:09.940022Z","shell.execute_reply.started":"2023-07-30T22:50:36.450919Z","shell.execute_reply":"2023-07-30T22:51:09.939000Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:32<00:00, 348.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.97739  |\n+-----------------+----------+\n| MRR             | 0.988152 |\n+-----------------+----------+\n| Macro Precision | 0.912892 |\n+-----------------+----------+\n| Macro Recall    | 0.73198  |\n+-----------------+----------+\n| Macro F1        | 0.781384 |\n+-----------------+----------+\n| Micro Precision | 0.888546 |\n+-----------------+----------+\n| Micro Recall    | 0.888546 |\n+-----------------+----------+\n| Micro F1        | 0.888546 |\n+-----------------+----------+\n| Accuracy        | 0.888546 |\n+-----------------+----------+\n| Golden Accuracy | 0.471037 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('joint_model_v3.pt', mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-07-30T22:53:23.046107Z","iopub.execute_input":"2023-07-30T22:53:23.046508Z","iopub.status.idle":"2023-07-30T22:53:56.971200Z","shell.execute_reply.started":"2023-07-30T22:53:23.046475Z","shell.execute_reply":"2023-07-30T22:53:56.970218Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:33<00:00, 343.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.97739  |\n+-----------------+----------+\n| MRR             | 0.988152 |\n+-----------------+----------+\n| Macro Precision | 0.87851  |\n+-----------------+----------+\n| Macro Recall    | 0.900688 |\n+-----------------+----------+\n| Macro F1        | 0.888935 |\n+-----------------+----------+\n| Micro Precision | 0.926807 |\n+-----------------+----------+\n| Micro Recall    | 0.926807 |\n+-----------------+----------+\n| Micro F1        | 0.926807 |\n+-----------------+----------+\n| Accuracy        | 0.926807 |\n+-----------------+----------+\n| Golden Accuracy | 0.857155 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('joint_model_v3.pt', mode='joint', threshold=0.35)","metadata":{"execution":{"iopub.status.busy":"2023-07-30T22:55:12.641606Z","iopub.execute_input":"2023-07-30T22:55:12.642555Z","iopub.status.idle":"2023-07-30T22:55:49.029010Z","shell.execute_reply.started":"2023-07-30T22:55:12.642521Z","shell.execute_reply":"2023-07-30T22:55:49.027061Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:35<00:00, 320.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.97739  |\n+-----------------+----------+\n| MRR             | 0.988152 |\n+-----------------+----------+\n| Macro Precision | 0.815863 |\n+-----------------+----------+\n| Macro Recall    | 0.908082 |\n+-----------------+----------+\n| Macro F1        | 0.846343 |\n+-----------------+----------+\n| Micro Precision | 0.886005 |\n+-----------------+----------+\n| Micro Recall    | 0.886005 |\n+-----------------+----------+\n| Micro F1        | 0.886005 |\n+-----------------+----------+\n| Accuracy        | 0.886005 |\n+-----------------+----------+\n| Golden Accuracy | 0.944878 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('joint_model_v3.pt', mode='joint', threshold=0.45)","metadata":{"execution":{"iopub.status.busy":"2023-07-30T22:55:49.031840Z","iopub.execute_input":"2023-07-30T22:55:49.032481Z","iopub.status.idle":"2023-07-30T22:56:24.326191Z","shell.execute_reply.started":"2023-07-30T22:55:49.032445Z","shell.execute_reply":"2023-07-30T22:56:24.325152Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:34<00:00, 330.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.97739  |\n+-----------------+----------+\n| MRR             | 0.988152 |\n+-----------------+----------+\n| Macro Precision | 0.910368 |\n+-----------------+----------+\n| Macro Recall    | 0.837427 |\n+-----------------+----------+\n| Macro F1        | 0.86744  |\n+-----------------+----------+\n| Micro Precision | 0.922443 |\n+-----------------+----------+\n| Micro Recall    | 0.922443 |\n+-----------------+----------+\n| Micro F1        | 0.922443 |\n+-----------------+----------+\n| Accuracy        | 0.922443 |\n+-----------------+----------+\n| Golden Accuracy | 0.695732 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('joint_model_v2.pt', mode='joint')","metadata":{"execution":{"iopub.status.busy":"2023-07-30T21:57:56.787875Z","iopub.execute_input":"2023-07-30T21:57:56.788278Z","iopub.status.idle":"2023-07-30T21:58:26.738132Z","shell.execute_reply.started":"2023-07-30T21:57:56.788247Z","shell.execute_reply":"2023-07-30T21:58:26.737117Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:29<00:00, 390.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.975287 |\n+-----------------+----------+\n| MRR             | 0.98709  |\n+-----------------+----------+\n| Macro Precision | 0.910495 |\n+-----------------+----------+\n| Macro Recall    | 0.724312 |\n+-----------------+----------+\n| Macro F1        | 0.773455 |\n+-----------------+----------+\n| Micro Precision | 0.885479 |\n+-----------------+----------+\n| Micro Recall    | 0.885479 |\n+-----------------+----------+\n| Micro F1        | 0.885479 |\n+-----------------+----------+\n| Accuracy        | 0.885479 |\n+-----------------+----------+\n| Golden Accuracy | 0.455701 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('joint_model.pt', mode='joint')","metadata":{"execution":{"iopub.status.busy":"2023-07-30T21:58:26.740132Z","iopub.execute_input":"2023-07-30T21:58:26.740838Z","iopub.status.idle":"2023-07-30T21:58:56.445083Z","shell.execute_reply.started":"2023-07-30T21:58:26.740804Z","shell.execute_reply":"2023-07-30T21:58:56.444096Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:29<00:00, 393.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.973359 |\n+-----------------+----------+\n| MRR             | 0.986031 |\n+-----------------+----------+\n| Macro Precision | 0.900758 |\n+-----------------+----------+\n| Macro Recall    | 0.702688 |\n+-----------------+----------+\n| Macro F1        | 0.749973 |\n+-----------------+----------+\n| Micro Precision | 0.876435 |\n+-----------------+----------+\n| Micro Recall    | 0.876435 |\n+-----------------+----------+\n| Micro F1        | 0.876435 |\n+-----------------+----------+\n| Accuracy        | 0.876435 |\n+-----------------+----------+\n| Golden Accuracy | 0.41311  |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('audio_text_model.pt', mode='audio')","metadata":{"execution":{"iopub.status.busy":"2023-07-30T19:17:25.138971Z","iopub.execute_input":"2023-07-30T19:17:25.139369Z","iopub.status.idle":"2023-07-30T19:17:49.545534Z","shell.execute_reply.started":"2023-07-30T19:17:25.139337Z","shell.execute_reply":"2023-07-30T19:17:49.544442Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:23<00:00, 481.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.972833 |\n+-----------------+----------+\n| MRR             | 0.985884 |\n+-----------------+----------+\n| Macro Precision | 0.889414 |\n+-----------------+----------+\n| Macro Recall    | 0.680834 |\n+-----------------+----------+\n| Macro F1        | 0.725007 |\n+-----------------+----------+\n| Micro Precision | 0.867233 |\n+-----------------+----------+\n| Micro Recall    | 0.867233 |\n+-----------------+----------+\n| Micro F1        | 0.867233 |\n+-----------------+----------+\n| Accuracy        | 0.867233 |\n+-----------------+----------+\n| Golden Accuracy | 0.370169 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('image_text_model.pt', mode='image')","metadata":{"execution":{"iopub.status.busy":"2023-07-30T19:17:49.547475Z","iopub.execute_input":"2023-07-30T19:17:49.547844Z","iopub.status.idle":"2023-07-30T19:18:11.775144Z","shell.execute_reply.started":"2023-07-30T19:17:49.547808Z","shell.execute_reply":"2023-07-30T19:18:11.774190Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:21<00:00, 529.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+-----------+\n| Metrics         |    Values |\n+=================+===========+\n| Hits@1          | 0.613268  |\n+-----------------+-----------+\n| MRR             | 0.777311  |\n+-----------------+-----------+\n| Macro Precision | 0.642991  |\n+-----------------+-----------+\n| Macro Recall    | 0.535437  |\n+-----------------+-----------+\n| Macro F1        | 0.523788  |\n+-----------------+-----------+\n| Micro Precision | 0.797862  |\n+-----------------+-----------+\n| Micro Recall    | 0.797862  |\n+-----------------+-----------+\n| Micro F1        | 0.797862  |\n+-----------------+-----------+\n| Accuracy        | 0.797862  |\n+-----------------+-----------+\n| Golden Accuracy | 0.0980633 |\n+-----------------+-----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('joint_model_50epochs.pt', mode='joint')","metadata":{"execution":{"iopub.status.busy":"2023-07-30T21:54:44.202934Z","iopub.execute_input":"2023-07-30T21:54:44.203304Z","iopub.status.idle":"2023-07-30T21:55:14.812344Z","shell.execute_reply.started":"2023-07-30T21:54:44.203273Z","shell.execute_reply":"2023-07-30T21:55:14.811422Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:29<00:00, 381.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.946806 |\n+-----------------+----------+\n| MRR             | 0.972094 |\n+-----------------+----------+\n| Macro Precision | 0.863804 |\n+-----------------+----------+\n| Macro Recall    | 0.647719 |\n+-----------------+----------+\n| Macro F1        | 0.684354 |\n+-----------------+----------+\n| Micro Precision | 0.852633 |\n+-----------------+----------+\n| Micro Recall    | 0.852633 |\n+-----------------+----------+\n| Micro F1        | 0.852633 |\n+-----------------+----------+\n| Accuracy        | 0.852633 |\n+-----------------+----------+\n| Golden Accuracy | 0.306196 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('audio_text_model_50epochs.pt', mode='audio')","metadata":{"execution":{"iopub.status.busy":"2023-07-30T21:55:14.814446Z","iopub.execute_input":"2023-07-30T21:55:14.815279Z","iopub.status.idle":"2023-07-30T21:55:37.770502Z","shell.execute_reply.started":"2023-07-30T21:55:14.815242Z","shell.execute_reply":"2023-07-30T21:55:37.769295Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:22<00:00, 513.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.947594 |\n+-----------------+----------+\n| MRR             | 0.972585 |\n+-----------------+----------+\n| Macro Precision | 0.850292 |\n+-----------------+----------+\n| Macro Recall    | 0.631901 |\n+-----------------+----------+\n| Macro F1        | 0.663924 |\n+-----------------+----------+\n| Micro Precision | 0.84578  |\n+-----------------+----------+\n| Micro Recall    | 0.84578  |\n+-----------------+----------+\n| Micro F1        | 0.84578  |\n+-----------------+----------+\n| Accuracy        | 0.84578  |\n+-----------------+----------+\n| Golden Accuracy | 0.275436 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('image_text_model_50epochs.pt', mode='image')","metadata":{"execution":{"iopub.status.busy":"2023-07-30T21:55:37.772230Z","iopub.execute_input":"2023-07-30T21:55:37.772931Z","iopub.status.idle":"2023-07-30T21:56:00.535049Z","shell.execute_reply.started":"2023-07-30T21:55:37.772896Z","shell.execute_reply":"2023-07-30T21:56:00.532542Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:22<00:00, 516.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+-----------+\n| Metrics         |    Values |\n+=================+===========+\n| Hits@1          | 0.581281  |\n+-----------------+-----------+\n| MRR             | 0.756557  |\n+-----------------+-----------+\n| Macro Precision | 0.627856  |\n+-----------------+-----------+\n| Macro Recall    | 0.531494  |\n+-----------------+-----------+\n| Macro F1        | 0.51776   |\n+-----------------+-----------+\n| Micro Precision | 0.795496  |\n+-----------------+-----------+\n| Micro Recall    | 0.795496  |\n+-----------------+-----------+\n| Micro F1        | 0.795496  |\n+-----------------+-----------+\n| Accuracy        | 0.795496  |\n+-----------------+-----------+\n| Golden Accuracy | 0.0914907 |\n+-----------------+-----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('joint_model_50epochs.pt', mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-07-30T23:01:08.200902Z","iopub.execute_input":"2023-07-30T23:01:08.201301Z","iopub.status.idle":"2023-07-30T23:01:43.882013Z","shell.execute_reply.started":"2023-07-30T23:01:08.201270Z","shell.execute_reply":"2023-07-30T23:01:43.880405Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:34<00:00, 327.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.946806 |\n+-----------------+----------+\n| MRR             | 0.972094 |\n+-----------------+----------+\n| Macro Precision | 0.804012 |\n+-----------------+----------+\n| Macro Recall    | 0.828762 |\n+-----------------+----------+\n| Macro F1        | 0.81528  |\n+-----------------+----------+\n| Micro Precision | 0.876873 |\n+-----------------+----------+\n| Micro Recall    | 0.876873 |\n+-----------------+----------+\n| Micro F1        | 0.876873 |\n+-----------------+----------+\n| Accuracy        | 0.876873 |\n+-----------------+----------+\n| Golden Accuracy | 0.748576 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('audio_text_model_50epochs.pt', mode='audio', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-07-30T23:01:43.885080Z","iopub.execute_input":"2023-07-30T23:01:43.886541Z","iopub.status.idle":"2023-07-30T23:02:09.494019Z","shell.execute_reply.started":"2023-07-30T23:01:43.886503Z","shell.execute_reply":"2023-07-30T23:02:09.492437Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:24<00:00, 458.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.947594 |\n+-----------------+----------+\n| MRR             | 0.972585 |\n+-----------------+----------+\n| Macro Precision | 0.784803 |\n+-----------------+----------+\n| Macro Recall    | 0.812078 |\n+-----------------+----------+\n| Macro F1        | 0.796969 |\n+-----------------+----------+\n| Micro Precision | 0.863693 |\n+-----------------+----------+\n| Micro Recall    | 0.863693 |\n+-----------------+----------+\n| Micro F1        | 0.863693 |\n+-----------------+----------+\n| Accuracy        | 0.863693 |\n+-----------------+----------+\n| Golden Accuracy | 0.726054 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('joint_model_50epochs_v2.pt', mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:36:59.348433Z","iopub.execute_input":"2023-07-31T10:36:59.349329Z","iopub.status.idle":"2023-07-31T10:37:28.869664Z","shell.execute_reply.started":"2023-07-31T10:36:59.349292Z","shell.execute_reply":"2023-07-31T10:37:28.868659Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:28<00:00, 395.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.964508 |\n+-----------------+----------+\n| MRR             | 0.981503 |\n+-----------------+----------+\n| Macro Precision | 0.831846 |\n+-----------------+----------+\n| Macro Recall    | 0.8587   |\n+-----------------+----------+\n| Macro F1        | 0.844114 |\n+-----------------+----------+\n| Micro Precision | 0.896118 |\n+-----------------+----------+\n| Micro Recall    | 0.896118 |\n+-----------------+----------+\n| Micro F1        | 0.896118 |\n+-----------------+----------+\n| Accuracy        | 0.896118 |\n+-----------------+----------+\n| Golden Accuracy | 0.796337 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('audio_text_model_50epochs_v2.pt', mode='audio', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:37:28.871981Z","iopub.execute_input":"2023-07-31T10:37:28.872737Z","iopub.status.idle":"2023-07-31T10:37:51.614325Z","shell.execute_reply.started":"2023-07-31T10:37:28.872700Z","shell.execute_reply":"2023-07-31T10:37:51.613295Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:22<00:00, 518.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.948646 |\n+-----------------+----------+\n| MRR             | 0.972874 |\n+-----------------+----------+\n| Macro Precision | 0.789402 |\n+-----------------+----------+\n| Macro Recall    | 0.814225 |\n+-----------------+----------+\n| Macro F1        | 0.800623 |\n+-----------------+----------+\n| Micro Precision | 0.866813 |\n+-----------------+----------+\n| Micro Recall    | 0.866813 |\n+-----------------+----------+\n| Micro F1        | 0.866813 |\n+-----------------+----------+\n| Accuracy        | 0.866813 |\n+-----------------+----------+\n| Golden Accuracy | 0.72658  |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('image_text_model_50epochs_v2.pt', mode='image', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:37:51.615930Z","iopub.execute_input":"2023-07-31T10:37:51.616562Z","iopub.status.idle":"2023-07-31T10:38:14.198992Z","shell.execute_reply.started":"2023-07-31T10:37:51.616525Z","shell.execute_reply":"2023-07-31T10:38:14.197986Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:21<00:00, 521.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.588555 |\n+-----------------+----------+\n| MRR             | 0.761233 |\n+-----------------+----------+\n| Macro Precision | 0.607948 |\n+-----------------+----------+\n| Macro Recall    | 0.618066 |\n+-----------------+----------+\n| Macro F1        | 0.612157 |\n+-----------------+----------+\n| Micro Precision | 0.739883 |\n+-----------------+----------+\n| Micro Recall    | 0.739883 |\n+-----------------+----------+\n| Micro F1        | 0.739883 |\n+-----------------+----------+\n| Accuracy        | 0.739883 |\n+-----------------+----------+\n| Golden Accuracy | 0.415038 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('joint_model_v4n_150.pt', mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:38:14.201661Z","iopub.execute_input":"2023-07-31T10:38:14.202378Z","iopub.status.idle":"2023-07-31T10:38:44.207329Z","shell.execute_reply.started":"2023-07-31T10:38:14.202339Z","shell.execute_reply":"2023-07-31T10:38:44.206177Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:29<00:00, 389.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.979581 |\n+-----------------+----------+\n| MRR             | 0.989358 |\n+-----------------+----------+\n| Macro Precision | 0.880296 |\n+-----------------+----------+\n| Macro Recall    | 0.903383 |\n+-----------------+----------+\n| Macro F1        | 0.891125 |\n+-----------------+----------+\n| Micro Precision | 0.928175 |\n+-----------------+----------+\n| Micro Recall    | 0.928175 |\n+-----------------+----------+\n| Micro F1        | 0.928175 |\n+-----------------+----------+\n| Accuracy        | 0.928175 |\n+-----------------+----------+\n| Golden Accuracy | 0.862063 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('joint_model_v4n_250.pt', mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T10:38:44.208990Z","iopub.execute_input":"2023-07-31T10:38:44.209376Z","iopub.status.idle":"2023-07-31T10:39:13.704307Z","shell.execute_reply.started":"2023-07-31T10:38:44.209340Z","shell.execute_reply":"2023-07-31T10:39:13.701786Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:28<00:00, 397.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.980195 |\n+-----------------+----------+\n| MRR             | 0.989687 |\n+-----------------+----------+\n| Macro Precision | 0.886623 |\n+-----------------+----------+\n| Macro Recall    | 0.907589 |\n+-----------------+----------+\n| Macro F1        | 0.896529 |\n+-----------------+----------+\n| Micro Precision | 0.93196  |\n+-----------------+----------+\n| Micro Recall    | 0.93196  |\n+-----------------+----------+\n| Micro F1        | 0.93196  |\n+-----------------+----------+\n| Accuracy        | 0.93196  |\n+-----------------+----------+\n| Golden Accuracy | 0.86697  |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 10 candidates","metadata":{}},{"cell_type":"code","source":"evaluate('joint_model_50epochs_v2.pt', mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:50:21.355074Z","iopub.execute_input":"2023-08-06T15:50:21.355495Z","iopub.status.idle":"2023-08-06T15:51:06.329684Z","shell.execute_reply.started":"2023-08-06T15:50:21.355456Z","shell.execute_reply":"2023-08-06T15:51:06.328272Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:43<00:00, 262.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.935063 |\n+-----------------+----------+\n| MRR             | 0.964547 |\n+-----------------+----------+\n| Macro Precision | 0.752523 |\n+-----------------+----------+\n| Macro Recall    | 0.858781 |\n+-----------------+----------+\n| Macro F1        | 0.791778 |\n+-----------------+----------+\n| Micro Precision | 0.908737 |\n+-----------------+----------+\n| Micro Recall    | 0.908737 |\n+-----------------+----------+\n| Micro F1        | 0.908737 |\n+-----------------+----------+\n| Accuracy        | 0.908737 |\n+-----------------+----------+\n| Golden Accuracy | 0.796337 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('audio_text_model_50epochs_v2.pt', mode='audio', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:51:06.332196Z","iopub.execute_input":"2023-08-06T15:51:06.332587Z","iopub.status.idle":"2023-08-06T15:51:42.866402Z","shell.execute_reply.started":"2023-08-06T15:51:06.332548Z","shell.execute_reply":"2023-08-06T15:51:42.865279Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:35<00:00, 324.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.904215 |\n+-----------------+----------+\n| MRR             | 0.946709 |\n+-----------------+----------+\n| Macro Precision | 0.711662 |\n+-----------------+----------+\n| Macro Recall    | 0.815105 |\n+-----------------+----------+\n| Macro F1        | 0.747342 |\n+-----------------+----------+\n| Micro Precision | 0.885926 |\n+-----------------+----------+\n| Micro Recall    | 0.885926 |\n+-----------------+----------+\n| Micro F1        | 0.885926 |\n+-----------------+----------+\n| Accuracy        | 0.885926 |\n+-----------------+----------+\n| Golden Accuracy | 0.72658  |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('image_text_model_50epochs_v2.pt', mode='image', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:51:42.867826Z","iopub.execute_input":"2023-08-06T15:51:42.868264Z","iopub.status.idle":"2023-08-06T15:52:20.414975Z","shell.execute_reply.started":"2023-08-06T15:51:42.868229Z","shell.execute_reply":"2023-08-06T15:52:20.413156Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:36<00:00, 315.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.39865  |\n+-----------------+----------+\n| MRR             | 0.610014 |\n+-----------------+----------+\n| Macro Precision | 0.566854 |\n+-----------------+----------+\n| Macro Recall    | 0.619125 |\n+-----------------+----------+\n| Macro F1        | 0.574039 |\n+-----------------+----------+\n| Micro Precision | 0.782394 |\n+-----------------+----------+\n| Micro Recall    | 0.782394 |\n+-----------------+----------+\n| Micro F1        | 0.782394 |\n+-----------------+----------+\n| Accuracy        | 0.782394 |\n+-----------------+----------+\n| Golden Accuracy | 0.415038 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluate('joint_model_v4n_250.pt', mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T15:52:20.417182Z","iopub.execute_input":"2023-08-06T15:52:20.417647Z","iopub.status.idle":"2023-08-06T15:53:04.010221Z","shell.execute_reply.started":"2023-08-06T15:52:20.417591Z","shell.execute_reply":"2023-08-06T15:53:04.008394Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:42<00:00, 271.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.963632 |\n+-----------------+----------+\n| MRR             | 0.980433 |\n+-----------------+----------+\n| Macro Precision | 0.821448 |\n+-----------------+----------+\n| Macro Recall    | 0.908475 |\n+-----------------+----------+\n| Macro F1        | 0.857663 |\n+-----------------+----------+\n| Micro Precision | 0.941679 |\n+-----------------+----------+\n| Micro Recall    | 0.941679 |\n+-----------------+----------+\n| Micro F1        | 0.941679 |\n+-----------------+----------+\n| Accuracy        | 0.941679 |\n+-----------------+----------+\n| Golden Accuracy | 0.86697  |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Multilingual","metadata":{}},{"cell_type":"code","source":"! pip install sentencepiece\n!pip install transformers\n!pip install -U sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:20:29.569988Z","iopub.execute_input":"2023-07-31T14:20:29.570650Z","iopub.status.idle":"2023-07-31T14:21:06.017286Z","shell.execute_reply.started":"2023-07-31T14:20:29.570616Z","shell.execute_reply":"2023-07-31T14:21:06.016150Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\nCollecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.30.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.65.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.23.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.1)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.16.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.6.3)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=42cd5a478cc4d285814a4515874aaa4481d61527df5c66e2a2b0d7eec2ec6464\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Copyright (c) 2022 Idiap Research Institute, http://www.idiap.ch/\n# Written by Alireza Mohammadshahi <alireza.mohammadshahi@idiap.ch>\n# This is a modified version of https://github.com/huggingface/transformers/blob/main/src/transformers/models/m2m_100/tokenization_m2m_100.py \n# which owns by Fariseq Authors and The HuggingFace Inc. team.\n#\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Tokenization classes for SMALL100.\"\"\"\nimport json\nimport os\nfrom pathlib import Path\nfrom shutil import copyfile\nfrom typing import Any, Dict, List, Optional, Tuple, Union\n\nimport sentencepiece\n\nfrom transformers.tokenization_utils import BatchEncoding, PreTrainedTokenizer\nfrom transformers.utils import logging\n\n\nlogger = logging.get_logger(__name__)\n\nSPIECE_UNDERLINE = \"▁\"\n\nVOCAB_FILES_NAMES = {\n    \"vocab_file\": \"vocab.json\",\n    \"spm_file\": \"sentencepiece.bpe.model\",\n    \"tokenizer_config_file\": \"tokenizer_config.json\",\n}\n\nPRETRAINED_VOCAB_FILES_MAP = {\n    \"vocab_file\": {\n        \"alirezamsh/small100\": \"https://huggingface.co/alirezamsh/small100/resolve/main/vocab.json\",\n    },\n    \"spm_file\": {\n        \"alirezamsh/small100\": \"https://huggingface.co/alirezamsh/small100/resolve/main/sentencepiece.bpe.model\",\n    },\n    \"tokenizer_config_file\": {\n        \"alirezamsh/small100\": \"https://huggingface.co/alirezamsh/small100/resolve/main/tokenizer_config.json\",\n    },\n}\n\nPRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n    \"alirezamsh/small100\": 1024,\n}\n\n# fmt: off\nFAIRSEQ_LANGUAGE_CODES = {\n    \"m2m100\": [\"af\", \"am\", \"ar\", \"ast\", \"az\", \"ba\", \"be\", \"bg\", \"bn\", \"br\", \"bs\", \"ca\", \"ceb\", \"cs\", \"cy\", \"da\", \"de\", \"el\", \"en\", \"es\", \"et\", \"fa\", \"ff\", \"fi\", \"fr\", \"fy\", \"ga\", \"gd\", \"gl\", \"gu\", \"ha\", \"he\", \"hi\", \"hr\", \"ht\", \"hu\", \"hy\", \"id\", \"ig\", \"ilo\", \"is\", \"it\", \"ja\", \"jv\", \"ka\", \"kk\", \"km\", \"kn\", \"ko\", \"lb\", \"lg\", \"ln\", \"lo\", \"lt\", \"lv\", \"mg\", \"mk\", \"ml\", \"mn\", \"mr\", \"ms\", \"my\", \"ne\", \"nl\", \"no\", \"ns\", \"oc\", \"or\", \"pa\", \"pl\", \"ps\", \"pt\", \"ro\", \"ru\", \"sd\", \"si\", \"sk\", \"sl\", \"so\", \"sq\", \"sr\", \"ss\", \"su\", \"sv\", \"sw\", \"ta\", \"th\", \"tl\", \"tn\", \"tr\", \"uk\", \"ur\", \"uz\", \"vi\", \"wo\", \"xh\", \"yi\", \"yo\", \"zh\", \"zu\"]\n}\n# fmt: on\n\n\nclass SMALL100Tokenizer(PreTrainedTokenizer):\n    \"\"\"\n    Construct an SMALL100 tokenizer. Based on [SentencePiece](https://github.com/google/sentencepiece).\n    This tokenizer inherits from [`PreTrainedTokenizer`] which contains most of the main methods. Users should refer to\n    this superclass for more information regarding those methods.\n    Args:\n        vocab_file (`str`):\n            Path to the vocabulary file.\n        spm_file (`str`):\n            Path to [SentencePiece](https://github.com/google/sentencepiece) file (generally has a .spm extension) that\n            contains the vocabulary.\n        tgt_lang (`str`, *optional*):\n            A string representing the target language.\n        eos_token (`str`, *optional*, defaults to `\"</s>\"`):\n            The end of sequence token.\n        sep_token (`str`, *optional*, defaults to `\"</s>\"`):\n            The separator token, which is used when building a sequence from multiple sequences, e.g. two sequences for\n            sequence classification or for a text and a question for question answering. It is also used as the last\n            token of a sequence built with special tokens.\n        unk_token (`str`, *optional*, defaults to `\"<unk>\"`):\n            The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this\n            token instead.\n        pad_token (`str`, *optional*, defaults to `\"<pad>\"`):\n            The token used for padding, for example when batching sequences of different lengths.\n        language_codes (`str`, *optional*):\n            What language codes to use. Should be `\"m2m100\"`.\n        sp_model_kwargs (`dict`, *optional*):\n            Will be passed to the `SentencePieceProcessor.__init__()` method. The [Python wrapper for\n            SentencePiece](https://github.com/google/sentencepiece/tree/master/python) can be used, among other things,\n            to set:\n            - `enable_sampling`: Enable subword regularization.\n            - `nbest_size`: Sampling parameters for unigram. Invalid for BPE-Dropout.\n              - `nbest_size = {0,1}`: No sampling is performed.\n              - `nbest_size > 1`: samples from the nbest_size results.\n              - `nbest_size < 0`: assuming that nbest_size is infinite and samples from the all hypothesis (lattice)\n                using forward-filtering-and-backward-sampling algorithm.\n            - `alpha`: Smoothing parameter for unigram sampling, and dropout probability of merge operations for\n              BPE-dropout.\n    Examples:\n    ```python\n    >>> from tokenization_small100 import SMALL100Tokenizer\n    >>> tokenizer = SMALL100Tokenizer.from_pretrained(\"alirezamsh/small100\", tgt_lang=\"ro\")\n    >>> src_text = \" UN Chief Says There Is No Military Solution in Syria\"\n    >>> tgt_text = \"Şeful ONU declară că nu există o soluţie militară în Siria\"\n    >>> model_inputs = tokenizer(src_text, text_target=tgt_text, return_tensors=\"pt\")\n    >>> model(**model_inputs)  # should work\n    ```\"\"\"\n\n    vocab_files_names = VOCAB_FILES_NAMES\n    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n    model_input_names = [\"input_ids\", \"attention_mask\"]\n\n    prefix_tokens: List[int] = []\n    suffix_tokens: List[int] = []\n\n    def __init__(\n        self,\n        vocab_file,\n        spm_file,\n        tgt_lang=None,\n        bos_token=\"<s>\",\n        eos_token=\"</s>\",\n        sep_token=\"</s>\",\n        pad_token=\"<pad>\",\n        unk_token=\"<unk>\",\n        language_codes=\"m2m100\",\n        sp_model_kwargs: Optional[Dict[str, Any]] = None,\n        num_madeup_words=8,\n        **kwargs,\n    ) -> None:\n        self.sp_model_kwargs = {} if sp_model_kwargs is None else sp_model_kwargs\n\n        self.language_codes = language_codes\n        fairseq_language_code = FAIRSEQ_LANGUAGE_CODES[language_codes]\n        self.lang_code_to_token = {lang_code: f\"__{lang_code}__\" for lang_code in fairseq_language_code}\n\n        kwargs[\"additional_special_tokens\"] = kwargs.get(\"additional_special_tokens\", [])\n        kwargs[\"additional_special_tokens\"] += [\n            self.get_lang_token(lang_code)\n            for lang_code in fairseq_language_code\n            if self.get_lang_token(lang_code) not in kwargs[\"additional_special_tokens\"]\n        ]\n\n        super().__init__(\n            tgt_lang=tgt_lang,\n            bos_token=bos_token,\n            eos_token=eos_token,\n            sep_token=sep_token,\n            unk_token=unk_token,\n            pad_token=pad_token,\n            language_codes=language_codes,\n            sp_model_kwargs=self.sp_model_kwargs,\n            num_madeup_words=num_madeup_words,\n            **kwargs,\n        )\n\n        self.vocab_file = vocab_file\n        self.encoder = load_json(vocab_file)\n        self.decoder = {v: k for k, v in self.encoder.items()}\n        self.spm_file = spm_file\n        self.sp_model = load_spm(spm_file, self.sp_model_kwargs)\n\n        self.encoder_size = len(self.encoder)\n\n        self.lang_token_to_id = {\n            self.get_lang_token(lang_code): self.encoder_size + i for i, lang_code in enumerate(fairseq_language_code)\n        }\n        self.lang_code_to_id = {lang_code: self.encoder_size + i for i, lang_code in enumerate(fairseq_language_code)}\n        self.id_to_lang_token = {v: k for k, v in self.lang_token_to_id.items()}\n\n        self._tgt_lang = tgt_lang if tgt_lang is not None else \"en\"\n        self.cur_lang_id = self.get_lang_id(self._tgt_lang)\n        self.set_lang_special_tokens(self._tgt_lang)\n\n        self.num_madeup_words = num_madeup_words\n\n    @property\n    def vocab_size(self) -> int:\n        return len(self.encoder) + len(self.lang_token_to_id) + self.num_madeup_words\n\n    @property\n    def tgt_lang(self) -> str:\n        return self._tgt_lang\n\n    @tgt_lang.setter\n    def tgt_lang(self, new_tgt_lang: str) -> None:\n        self._tgt_lang = new_tgt_lang\n        self.set_lang_special_tokens(self._tgt_lang)\n\n    def _tokenize(self, text: str) -> List[str]:\n        return self.sp_model.encode(text, out_type=str)\n\n    def _convert_token_to_id(self, token):\n        if token in self.lang_token_to_id:\n            return self.lang_token_to_id[token]\n        return self.encoder.get(token, self.encoder[self.unk_token])\n\n    def _convert_id_to_token(self, index: int) -> str:\n        \"\"\"Converts an index (integer) in a token (str) using the decoder.\"\"\"\n        if index in self.id_to_lang_token:\n            return self.id_to_lang_token[index]\n        return self.decoder.get(index, self.unk_token)\n\n    def convert_tokens_to_string(self, tokens: List[str]) -> str:\n        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n        return self.sp_model.decode(tokens)\n\n    def get_special_tokens_mask(\n        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None, already_has_special_tokens: bool = False\n    ) -> List[int]:\n        \"\"\"\n        Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer `prepare_for_model` method.\n        Args:\n            token_ids_0 (`List[int]`):\n                List of IDs.\n            token_ids_1 (`List[int]`, *optional*):\n                Optional second list of IDs for sequence pairs.\n            already_has_special_tokens (`bool`, *optional*, defaults to `False`):\n                Whether or not the token list is already formatted with special tokens for the model.\n        Returns:\n            `List[int]`: A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.\n        \"\"\"\n\n        if already_has_special_tokens:\n            return super().get_special_tokens_mask(\n                token_ids_0=token_ids_0, token_ids_1=token_ids_1, already_has_special_tokens=True\n            )\n\n        prefix_ones = [1] * len(self.prefix_tokens)\n        suffix_ones = [1] * len(self.suffix_tokens)\n        if token_ids_1 is None:\n            return prefix_ones + ([0] * len(token_ids_0)) + suffix_ones\n        return prefix_ones + ([0] * len(token_ids_0)) + ([0] * len(token_ids_1)) + suffix_ones\n\n    def build_inputs_with_special_tokens(\n        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n    ) -> List[int]:\n        \"\"\"\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and\n        adding special tokens. An MBART sequence has the following format, where `X` represents the sequence:\n        - `input_ids` (for encoder) `X [eos, src_lang_code]`\n        - `decoder_input_ids`: (for decoder) `X [eos, tgt_lang_code]`\n        BOS is never used. Pairs of sequences are not the expected use case, but they will be handled without a\n        separator.\n        Args:\n            token_ids_0 (`List[int]`):\n                List of IDs to which the special tokens will be added.\n            token_ids_1 (`List[int]`, *optional*):\n                Optional second list of IDs for sequence pairs.\n        Returns:\n            `List[int]`: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.\n        \"\"\"\n        if token_ids_1 is None:\n            if self.prefix_tokens is None:\n                return token_ids_0 + self.suffix_tokens\n            else:\n                return self.prefix_tokens + token_ids_0 + self.suffix_tokens\n        # We don't expect to process pairs, but leave the pair logic for API consistency\n        if self.prefix_tokens is None:\n            return token_ids_0 + token_ids_1 + self.suffix_tokens\n        else:\n            return self.prefix_tokens + token_ids_0 + token_ids_1 + self.suffix_tokens\n\n    def get_vocab(self) -> Dict:\n        vocab = {self.convert_ids_to_tokens(i): i for i in range(self.vocab_size)}\n        vocab.update(self.added_tokens_encoder)\n        return vocab\n\n    def __getstate__(self) -> Dict:\n        state = self.__dict__.copy()\n        state[\"sp_model\"] = None\n        return state\n\n    def __setstate__(self, d: Dict) -> None:\n        self.__dict__ = d\n\n        # for backward compatibility\n        if not hasattr(self, \"sp_model_kwargs\"):\n            self.sp_model_kwargs = {}\n\n        self.sp_model = load_spm(self.spm_file, self.sp_model_kwargs)\n\n    def save_vocabulary(self, save_directory: str, filename_prefix: Optional[str] = None) -> Tuple[str]:\n        save_dir = Path(save_directory)\n        if not save_dir.is_dir():\n            raise OSError(f\"{save_directory} should be a directory\")\n        vocab_save_path = save_dir / (\n            (filename_prefix + \"-\" if filename_prefix else \"\") + self.vocab_files_names[\"vocab_file\"]\n        )\n        spm_save_path = save_dir / (\n            (filename_prefix + \"-\" if filename_prefix else \"\") + self.vocab_files_names[\"spm_file\"]\n        )\n\n        save_json(self.encoder, vocab_save_path)\n\n        if os.path.abspath(self.spm_file) != os.path.abspath(spm_save_path) and os.path.isfile(self.spm_file):\n            copyfile(self.spm_file, spm_save_path)\n        elif not os.path.isfile(self.spm_file):\n            with open(spm_save_path, \"wb\") as fi:\n                content_spiece_model = self.sp_model.serialized_model_proto()\n                fi.write(content_spiece_model)\n\n        return (str(vocab_save_path), str(spm_save_path))\n\n    def prepare_seq2seq_batch(\n        self,\n        src_texts: List[str],\n        tgt_texts: Optional[List[str]] = None,\n        tgt_lang: str = \"ro\",\n        **kwargs,\n    ) -> BatchEncoding:\n        self.tgt_lang = tgt_lang\n        self.set_lang_special_tokens(self.tgt_lang)\n        return super().prepare_seq2seq_batch(src_texts, tgt_texts, **kwargs)\n\n    def _build_translation_inputs(self, raw_inputs, tgt_lang: Optional[str], **extra_kwargs):\n        \"\"\"Used by translation pipeline, to prepare inputs for the generate function\"\"\"\n        if tgt_lang is None:\n            raise ValueError(\"Translation requires a `tgt_lang` for this model\")\n        self.tgt_lang = tgt_lang\n        inputs = self(raw_inputs, add_special_tokens=True, **extra_kwargs)\n        return inputs\n\n    def _switch_to_input_mode(self):\n        self.set_lang_special_tokens(self.tgt_lang)\n\n    def _switch_to_target_mode(self):\n        self.prefix_tokens = None\n        self.suffix_tokens = [self.eos_token_id]        \n\n    def set_lang_special_tokens(self, src_lang: str) -> None:\n        \"\"\"Reset the special tokens to the tgt lang setting. No prefix and suffix=[eos, tgt_lang_code].\"\"\"\n        lang_token = self.get_lang_token(src_lang)\n        self.cur_lang_id = self.lang_token_to_id[lang_token]\n        self.prefix_tokens = [self.cur_lang_id]\n        self.suffix_tokens = [self.eos_token_id]\n\n    def get_lang_token(self, lang: str) -> str:\n        return self.lang_code_to_token[lang]\n\n    def get_lang_id(self, lang: str) -> int:\n        lang_token = self.get_lang_token(lang)\n        return self.lang_token_to_id[lang_token]\n\n\ndef load_spm(path: str, sp_model_kwargs: Dict[str, Any]) -> sentencepiece.SentencePieceProcessor:\n    spm = sentencepiece.SentencePieceProcessor(**sp_model_kwargs)\n    spm.Load(str(path))\n    return spm\n\n\ndef load_json(path: str) -> Union[Dict, List]:\n    with open(path, \"r\") as f:\n        return json.load(f)\n\n\ndef save_json(data, path: str) -> None:\n    with open(path, \"w\") as f:\n        json.dump(data, f, indent=2)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:21:06.019636Z","iopub.execute_input":"2023-07-31T14:21:06.020040Z","iopub.status.idle":"2023-07-31T14:21:07.605747Z","shell.execute_reply.started":"2023-07-31T14:21:06.020004Z","shell.execute_reply":"2023-07-31T14:21:07.604604Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from transformers import M2M100ForConditionalGeneration\n\n\nmodel = M2M100ForConditionalGeneration.from_pretrained(\"alirezamsh/small100\").to(device)\ntokenizer = SMALL100Tokenizer.from_pretrained(\"alirezamsh/small100\")","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:21:07.607238Z","iopub.execute_input":"2023-07-31T14:21:07.607949Z","iopub.status.idle":"2023-07-31T14:22:12.181023Z","shell.execute_reply.started":"2023-07-31T14:21:07.607907Z","shell.execute_reply":"2023-07-31T14:22:12.179958Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/890 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7959763836a468ebab6f0df7d240714"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"544c25b8fd394bbfad7aa8021fa918ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/3.71M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47cdfca8cef74e41a82f917bdf0da988"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"168fb2ba9c304364bb0799d7b03657cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/1.87k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb027d88d12447b29f95c4b564c431ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e372a1776a045ec99a4d663c8ae514a"}},"metadata":{}},{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'M2M100Tokenizer'. \nThe class this function is called from is 'SMALL100Tokenizer'.\n","output_type":"stream"}]},{"cell_type":"code","source":"def translate(text, target_lang='fa'):\n    tokenizer.tgt_lang = target_lang\n    encoded_zh = tokenizer(text, return_tensors=\"pt\", padding=True).to(device)\n    generated_tokens = model.generate(**encoded_zh)\n    return tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:22:12.182709Z","iopub.execute_input":"2023-07-31T14:22:12.183148Z","iopub.status.idle":"2023-07-31T14:22:12.189988Z","shell.execute_reply.started":"2023-07-31T14:22:12.183112Z","shell.execute_reply":"2023-07-31T14:22:12.188882Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"translate(['hi i am good', 'this is water'])","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:22:12.191588Z","iopub.execute_input":"2023-07-31T14:22:12.192048Z","iopub.status.idle":"2023-07-31T14:22:14.013004Z","shell.execute_reply.started":"2023-07-31T14:22:12.192014Z","shell.execute_reply":"2023-07-31T14:22:14.012023Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (256) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['سلام من خوب هستم', 'این آب است']"},"metadata":{}}]},{"cell_type":"code","source":"translate(['سلام من خوب هستم', 'این آب است'], target_lang='en')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:22:14.014553Z","iopub.execute_input":"2023-07-31T14:22:14.017498Z","iopub.status.idle":"2023-07-31T14:22:14.099710Z","shell.execute_reply.started":"2023-07-31T14:22:14.017461Z","shell.execute_reply":"2023-07-31T14:22:14.098745Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['Hello I am fine.', 'This is water.']"},"metadata":{}}]},{"cell_type":"markdown","source":"## prepare dataset","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\ntext_model = SentenceTransformer('sentence-transformers/LaBSE').to(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:22:14.103017Z","iopub.execute_input":"2023-07-31T14:22:14.103350Z","iopub.status.idle":"2023-07-31T14:22:32.545431Z","shell.execute_reply.started":"2023-07-31T14:22:14.103324Z","shell.execute_reply":"2023-07-31T14:22:32.544397Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)be010/.gitattributes:   0%|          | 0.00/391 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97884c7420dd4c59a2f773df327b8b59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87bda0be3e0e48b4a0ab20af7965437f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/2_Dense/config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7796715d54be4503b42e09d79f44ad90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/2.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c59f56171f5407bb9a1d40f1a387a83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)168ebbe010/README.md:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac9e76a248bb4a759f7630d414d0fcad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)8ebbe010/config.json:   0%|          | 0.00/804 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d15184b1367d4db59dd747d022fdeeac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c809096bb6ac49888b41e6e4c8ddaa89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/1.88G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"981136fe032240c1b2964cbeb84f61f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d2e6a98d976494bbdae2c87647cd4e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1e5994ef39f4ba78c7cb4296a981b72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)be010/tokenizer.json:   0%|          | 0.00/9.62M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c84cff617e643418b5e3c4c90f87368"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"963193594dee481792f67da24a688dbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)168ebbe010/vocab.txt:   0%|          | 0.00/5.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bce43f324914880b18b03b398db3b88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ebbe010/modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0a1fae0f4d54624836d50868bcf7894"}},"metadata":{}}]},{"cell_type":"code","source":"a = text_model.encode(translate(['hi i am good', 'this is water']))","metadata":{"execution":{"iopub.status.busy":"2023-07-31T14:22:32.547043Z","iopub.execute_input":"2023-07-31T14:22:32.547474Z","iopub.status.idle":"2023-07-31T14:22:32.671914Z","shell.execute_reply.started":"2023-07-31T14:22:32.547434Z","shell.execute_reply":"2023-07-31T14:22:32.670966Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1192074e79194754b8aa635e11692d66"}},"metadata":{}}]},{"cell_type":"code","source":"a.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:45:04.848604Z","iopub.execute_input":"2023-07-31T13:45:04.849302Z","iopub.status.idle":"2023-07-31T13:45:04.861632Z","shell.execute_reply.started":"2023-07-31T13:45:04.849261Z","shell.execute_reply":"2023-07-31T13:45:04.860452Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(2, 768)"},"metadata":{}}]},{"cell_type":"code","source":"for i in a:\n    print(i.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T13:48:16.016397Z","iopub.execute_input":"2023-07-31T13:48:16.016763Z","iopub.status.idle":"2023-07-31T13:48:16.024073Z","shell.execute_reply.started":"2023-07-31T13:48:16.016733Z","shell.execute_reply":"2023-07-31T13:48:16.022923Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"(768,)\n(768,)\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('total_dataset_v2_with_text.pkl', 'rb') as f:\n    total_dataset = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T16:24:34.085728Z","iopub.execute_input":"2023-08-06T16:24:34.086829Z","iopub.status.idle":"2023-08-06T16:24:59.777979Z","shell.execute_reply.started":"2023-08-06T16:24:34.086781Z","shell.execute_reply":"2023-08-06T16:24:59.776430Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"total_dataset['train'].keys()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T16:24:59.799212Z","iopub.execute_input":"2023-08-06T16:24:59.799550Z","iopub.status.idle":"2023-08-06T16:24:59.805707Z","shell.execute_reply.started":"2023-08-06T16:24:59.799520Z","shell.execute_reply":"2023-08-06T16:24:59.804534Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"dict_keys(['audio', 'image', 'text', 'pure-text'])"},"metadata":{}}]},{"cell_type":"code","source":"test_len_data = len(total_dataset['test']['text'])\n\nnumber_of_candidates_per_sample = 5\ntest_metadata = []\n\nfor index in range(test_len_data):\n    candidate_indexes = random.sample([i for i in range(test_len_data) if i != index], number_of_candidates_per_sample - 1)\n    candidate_indexes += [index]\n    test_metadata.append(candidate_indexes)\nlen(test_metadata)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T16:24:59.807762Z","iopub.execute_input":"2023-08-06T16:24:59.808360Z","iopub.status.idle":"2023-08-06T16:25:10.310465Z","shell.execute_reply.started":"2023-08-06T16:24:59.808324Z","shell.execute_reply":"2023-08-06T16:25:10.309475Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"11411"},"metadata":{}}]},{"cell_type":"code","source":"class TestDatasetV2(Dataset):\n    def __init__(self, test_dataset, metadata, target_lang='fa', load=False, batch_size=128):\n        self.data = test_dataset\n        if load:\n            with open(f'translated-text-embeddings-test-{target_lang}.pkl', 'rb') as f:\n                self.data['translated-text-embeddings'] = pickle.load(f)\n        else:\n            self.data['translated-text-embeddings'] = []\n            for s in tqdm(self.batch(self.data['pure-text'], batch_size)):\n                self.data['translated-text-embeddings'].extend(torch.Tensor(text_model.encode(translate(s, target_lang))))\n            with open(f'translated-text-embeddings-test-{target_lang}.pkl', 'wb') as f:\n                pickle.dump(self.data['translated-text-embeddings'], f)\n        \n        self.data['translated-text-embeddings'] = torch.stack(self.data['translated-text-embeddings'])\n        self.data['translated-text-embeddings'] = F.normalize(self.data['translated-text-embeddings'], dim=1)\n    \n        \n        \n        self.metadata = metadata\n        self.target_lang = target_lang\n        \n\n    def batch(self, iterable, n=1):\n        l = len(iterable)\n        for ndx in range(0, l, n):\n            yield iterable[ndx:min(ndx + n, l)]\n\n    def __len__(self):\n        return len(self.metadata)\n\n    def __getitem__(self, index):\n        candidate_indexes = self.metadata[index]\n        text = self.data['pure-text'][index]\n#         text_embedding = self.data['text'][index]\n        text_embedding = self.data['translated-text-embeddings'][index]\n        audio_embeddings = [self.data['audio'][i] for i in candidate_indexes]\n        image_embeddings = [self.data['image'][i] for i in candidate_indexes]\n        label_index = 4\n        audio_embeddings = torch.stack(audio_embeddings)\n        image_embeddings = torch.stack(image_embeddings)\n\n        return text_embedding, audio_embeddings, image_embeddings, label_index","metadata":{"execution":{"iopub.status.busy":"2023-08-06T16:25:10.328203Z","iopub.execute_input":"2023-08-06T16:25:10.328661Z","iopub.status.idle":"2023-08-06T16:25:10.345181Z","shell.execute_reply.started":"2023-08-06T16:25:10.328611Z","shell.execute_reply":"2023-08-06T16:25:10.344252Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"def evaluate(model_path, test_final_loader, mode='joint', threshold=0.5):\n    model = torch.load(model_path)\n    model.eval()\n    model = model.to(device)\n\n    def compute_cosine_similarity(embedding1: torch.Tensor, embedding2: torch.Tensor) -> float:\n        similarity = cosine_similarity(embedding1.unsqueeze(0), embedding2.unsqueeze(0)).item()\n        return similarity\n\n    def cosine_similarity(embedding1, embedding2):\n        dim = 1\n        embedding1 = F.normalize(embedding1, p=2, dim=dim)\n        embedding2 = F.normalize(embedding2, p=2, dim=dim)\n\n        dot_product = torch.sum(embedding1 * embedding2, dim=dim)\n\n        magnitude1 = torch.norm(embedding1, p=2, dim=dim)\n        magnitude2 = torch.norm(embedding2, p=2, dim=dim)\n\n        cosine_sim = dot_product / (magnitude1 * magnitude2)\n\n        return cosine_sim\n    \n    def _evaluate(model, dataloader, threshold=0.5, mode='joint'):\n        total_hits_1 = 0\n        total_mrr = 0\n        total_instances = 0\n        total_labels = []\n        total_predictions = []\n        number_of_golden_predictions = 0\n\n        with torch.no_grad():\n            for text_embedding, audio_candidates, image_candidates, label in tqdm(dataloader):\n                label = label[0]\n                text_embedding = text_embedding[0].to(device)\n                label = label.to(device)\n\n                if mode == 'joint':   \n                    audio_candidates = audio_candidates[0]\n                    audio_candidates = audio_candidates.to(device)\n                    \n                    image_candidates = image_candidates[0]\n                    image_candidates = image_candidates.to(device)\n                    final_embs = model(audio_candidates, image_candidates)\n                elif mode == 'audio':\n                    audio_candidates = audio_candidates[0]\n                    audio_candidates = audio_candidates.to(device)\n                    final_embs = model(audio_candidates)\n                elif mode == 'image':\n                    image_candidates = image_candidates[0]\n                    image_candidates = image_candidates.to(device)\n                    final_embs = model(image_candidates)    \n                \n                text_candidate_cosine_similarities = [compute_cosine_similarity(text_embedding, item) for item in final_embs]\n                predicted_idx = np.argmax(text_candidate_cosine_similarities)\n                \n                label_similarity = text_candidate_cosine_similarities[label.item()]\n\n                # Compute Hits@1\n                if predicted_idx == label.item():   \n                    total_hits_1 += 1\n\n                # Compute MRR\n                label_rank = sum([1 for x in text_candidate_cosine_similarities if x > text_candidate_cosine_similarities[label.item()]])\n                reciprocal_rank = 1 / (label_rank + 1)\n                total_mrr += reciprocal_rank\n\n                # Record predictions and labels\n                predictions = [0 if sim < threshold else 1 for sim in text_candidate_cosine_similarities]\n                total_labels.extend([0 if i != label.item() else 1 for i in range(len(text_candidate_cosine_similarities))])\n                total_predictions.extend(predictions)\n                if label_similarity >= threshold:\n                    number_of_golden_predictions += 1\n\n                total_instances += 1\n\n        # Compute average metrics over all instances\n        avg_hits_1 = total_hits_1 / total_instances\n        avg_mrr = total_mrr / total_instances\n        precision = precision_score(total_labels, total_predictions, average='macro')\n        recall = recall_score(total_labels, total_predictions, average='macro')\n        f1 = f1_score(total_labels, total_predictions, average='macro')\n        precision_micro = precision_score(total_labels, total_predictions, average='micro')\n        recall_micro = recall_score(total_labels, total_predictions, average='micro')\n        f1_micro = f1_score(total_labels, total_predictions, average='micro')\n        accuracy = accuracy_score(total_labels, total_predictions)\n        golden_prediction_accuracy = number_of_golden_predictions / total_instances\n\n        return {\n            'Hits@1': avg_hits_1,\n            'MRR': avg_mrr,\n            'Macro Precision': precision,\n            'Macro Recall': recall,\n            'Macro F1': f1,\n            'Micro Precision': precision_micro,\n            'Micro Recall': recall_micro,\n            'Micro F1': f1_micro,\n            'Accuracy': accuracy,\n            'Golden Accuracy': golden_prediction_accuracy,\n        }\n    \n    results = _evaluate(model, test_final_loader, threshold=threshold, mode=mode)\n    table = []\n    for i in range(len(results)):\n        table.append([list(results.keys())[i], list(results.values())[i]])\n    print(tabulate(table, ['Metrics', 'Values'], tablefmt=\"grid\"))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-06T16:25:10.346593Z","iopub.execute_input":"2023-08-06T16:25:10.347441Z","iopub.status.idle":"2023-08-06T16:25:10.373001Z","shell.execute_reply.started":"2023-08-06T16:25:10.347403Z","shell.execute_reply":"2023-08-06T16:25:10.371939Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()\ntorch.cuda.ipc_collect()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T16:25:10.374555Z","iopub.execute_input":"2023-08-06T16:25:10.375001Z","iopub.status.idle":"2023-08-06T16:25:11.268931Z","shell.execute_reply.started":"2023-08-06T16:25:10.374966Z","shell.execute_reply":"2023-08-06T16:25:11.267710Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDatasetV2(total_dataset['test'], test_metadata, load=True,  target_lang='fa')\ntest_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\nevaluate('joint_model_translation_v2.pt', test_final_loader, mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T16:30:34.502709Z","iopub.execute_input":"2023-08-06T16:30:34.503928Z","iopub.status.idle":"2023-08-06T16:31:13.971052Z","shell.execute_reply.started":"2023-08-06T16:30:34.503879Z","shell.execute_reply":"2023-08-06T16:31:13.968964Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:31<00:00, 363.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.908159 |\n+-----------------+----------+\n| MRR             | 0.947828 |\n+-----------------+----------+\n| Macro Precision | 0.727722 |\n+-----------------+----------+\n| Macro Recall    | 0.834261 |\n+-----------------+----------+\n| Macro F1        | 0.741498 |\n+-----------------+----------+\n| Micro Precision | 0.787766 |\n+-----------------+----------+\n| Micro Recall    | 0.787766 |\n+-----------------+----------+\n| Micro F1        | 0.787766 |\n+-----------------+----------+\n| Accuracy        | 0.787766 |\n+-----------------+----------+\n| Golden Accuracy | 0.911752 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dataset = TestDatasetV2(total_dataset['test'], test_metadata, load=True,  target_lang='de')\ntest_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\nevaluate('joint_model_translation_v2.pt', test_final_loader, mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T16:31:22.309795Z","iopub.execute_input":"2023-08-06T16:31:22.310212Z","iopub.status.idle":"2023-08-06T16:31:59.845360Z","shell.execute_reply.started":"2023-08-06T16:31:22.310169Z","shell.execute_reply":"2023-08-06T16:31:59.844352Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:29<00:00, 385.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.93033  |\n+-----------------+----------+\n| MRR             | 0.961336 |\n+-----------------+----------+\n| Macro Precision | 0.702781 |\n+-----------------+----------+\n| Macro Recall    | 0.813842 |\n+-----------------+----------+\n| Macro F1        | 0.692707 |\n+-----------------+----------+\n| Micro Precision | 0.730067 |\n+-----------------+----------+\n| Micro Recall    | 0.730067 |\n+-----------------+----------+\n| Micro F1        | 0.730067 |\n+-----------------+----------+\n| Accuracy        | 0.730067 |\n+-----------------+----------+\n| Golden Accuracy | 0.953466 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dataset = TestDatasetV2(total_dataset['test'], test_metadata, load=True,  target_lang='fr')\ntest_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\nevaluate('joint_model_translation_v2.pt', test_final_loader, mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T16:31:59.847539Z","iopub.execute_input":"2023-08-06T16:31:59.848163Z","iopub.status.idle":"2023-08-06T16:32:37.483742Z","shell.execute_reply.started":"2023-08-06T16:31:59.848127Z","shell.execute_reply":"2023-08-06T16:32:37.482540Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:29<00:00, 385.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.943037 |\n+-----------------+----------+\n| MRR             | 0.968783 |\n+-----------------+----------+\n| Macro Precision | 0.758813 |\n+-----------------+----------+\n| Macro Recall    | 0.867047 |\n+-----------------+----------+\n| Macro F1        | 0.781437 |\n+-----------------+----------+\n| Micro Precision | 0.82608  |\n+-----------------+----------+\n| Micro Recall    | 0.82608  |\n+-----------------+----------+\n| Micro F1        | 0.82608  |\n+-----------------+----------+\n| Accuracy        | 0.82608  |\n+-----------------+----------+\n| Golden Accuracy | 0.935326 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dataset = TestDatasetV2(total_dataset['test'], test_metadata, load=True,  target_lang='zh')\ntest_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\nevaluate('joint_model_translation_v2.pt', test_final_loader, mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T16:32:37.485334Z","iopub.execute_input":"2023-08-06T16:32:37.486318Z","iopub.status.idle":"2023-08-06T16:33:15.227842Z","shell.execute_reply.started":"2023-08-06T16:32:37.486280Z","shell.execute_reply":"2023-08-06T16:33:15.226690Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:30<00:00, 379.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.904829 |\n+-----------------+----------+\n| MRR             | 0.946153 |\n+-----------------+----------+\n| Macro Precision | 0.866581 |\n+-----------------+----------+\n| Macro Recall    | 0.770167 |\n+-----------------+----------+\n| Macro F1        | 0.805246 |\n+-----------------+----------+\n| Micro Precision | 0.890965 |\n+-----------------+----------+\n| Micro Recall    | 0.890965 |\n+-----------------+----------+\n| Micro F1        | 0.890965 |\n+-----------------+----------+\n| Accuracy        | 0.890965 |\n+-----------------+----------+\n| Golden Accuracy | 0.568837 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"# persian\nevaluate('joint_model_v4n_250.pt', test_final_loader, mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T15:48:21.725992Z","iopub.execute_input":"2023-07-31T15:48:21.726999Z","iopub.status.idle":"2023-07-31T15:48:53.938154Z","shell.execute_reply.started":"2023-07-31T15:48:21.726962Z","shell.execute_reply":"2023-07-31T15:48:53.936070Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:31<00:00, 362.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.905705 |\n+-----------------+----------+\n| MRR             | 0.946227 |\n+-----------------+----------+\n| Macro Precision | 0.726908 |\n+-----------------+----------+\n| Macro Recall    | 0.833297 |\n+-----------------+----------+\n| Macro F1        | 0.740438 |\n+-----------------+----------+\n| Micro Precision | 0.78675  |\n+-----------------+----------+\n| Micro Recall    | 0.78675  |\n+-----------------+----------+\n| Micro F1        | 0.78675  |\n+-----------------+----------+\n| Accuracy        | 0.78675  |\n+-----------------+----------+\n| Golden Accuracy | 0.910875 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dataset = TestDatasetV2(total_dataset['test'], test_metadata, target_lang='fr', batch_size=32)\ntest_final_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate('joint_model_v4n_250.pt', test_final_loader, mode='joint', threshold=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T16:06:44.667999Z","iopub.execute_input":"2023-07-31T16:06:44.668396Z","iopub.status.idle":"2023-07-31T16:07:17.885991Z","shell.execute_reply.started":"2023-07-31T16:06:44.668362Z","shell.execute_reply":"2023-07-31T16:07:17.884949Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stderr","text":"100%|██████████| 11411/11411 [00:31<00:00, 358.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"+-----------------+----------+\n| Metrics         |   Values |\n+=================+==========+\n| Hits@1          | 0.942862 |\n+-----------------+----------+\n| MRR             | 0.968969 |\n+-----------------+----------+\n| Macro Precision | 0.756369 |\n+-----------------+----------+\n| Macro Recall    | 0.863947 |\n+-----------------+----------+\n| Macro F1        | 0.778564 |\n+-----------------+----------+\n| Micro Precision | 0.823644 |\n+-----------------+----------+\n| Micro Recall    | 0.823644 |\n+-----------------+----------+\n| Micro F1        | 0.823644 |\n+-----------------+----------+\n| Accuracy        | 0.823644 |\n+-----------------+----------+\n| Golden Accuracy | 0.931119 |\n+-----------------+----------+\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}