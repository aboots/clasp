{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n!pip install opendatasets\n!pip install pydub\n!pip install gdown\n!pip install -U sentence-transformers\n!pip install resampy","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-07-24T20:23:19.327241Z","iopub.execute_input":"2023-07-24T20:23:19.327681Z","iopub.status.idle":"2023-07-24T20:24:39.048664Z","shell.execute_reply.started":"2023-07-24T20:23:19.327644Z","shell.execute_reply":"2023-07-24T20:24:39.047406Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\nCollecting opendatasets\n  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from opendatasets) (4.65.0)\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (from opendatasets) (1.5.15)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from opendatasets) (8.1.3)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (1.16.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (2023.5.7)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (2.8.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (2.31.0)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (8.0.1)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (1.26.15)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle->opendatasets) (6.0.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle->opendatasets) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->opendatasets) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->opendatasets) (3.4)\nInstalling collected packages: opendatasets\nSuccessfully installed opendatasets-0.1.22\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (0.25.1)\nCollecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.65.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\nCollecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.30.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.65.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.23.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.1)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.16.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.6.3)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=54a9ffe7ff9e24e72bb665a522e0f01204b2f80097bd671023390d40979ef8c7\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\nCollecting resampy\n  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from resampy) (1.23.5)\nRequirement already satisfied: numba>=0.53 in /opt/conda/lib/python3.10/site-packages (from resampy) (0.57.1)\nRequirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.53->resampy) (0.40.1)\nInstalling collected packages: resampy\nSuccessfully installed resampy-0.4.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport resampy\nfrom transformers import AutoProcessor, Wav2Vec2Model\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModel\nimport numpy as np\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom sklearn.model_selection import train_test_split\nfrom time import time\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import accuracy_score\nimport os\nfrom pydub import AudioSegment\nimport opendatasets as od\nimport pandas as pd\nimport gc\nimport random\nimport pickle\nimport gdown\nimport json\nfrom nltk import word_tokenize\nimport string\nfrom zipfile import ZipFile\nfrom torch.nn.functional import cosine_similarity\nfrom tabulate import tabulate\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport torchvision.models as models\nimport torchvision.transforms.functional as F\nfrom PIL import Image\nimport cv2\nfrom sentence_transformers import SentenceTransformer\nfrom IPython.display import FileLink\nfrom shutil import rmtree\nfrom datasets import load_dataset\nfrom IPython.display import Audio, display\nimport torchaudio","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:24:39.051530Z","iopub.execute_input":"2023-07-24T20:24:39.051937Z","iopub.status.idle":"2023-07-24T20:24:57.034082Z","shell.execute_reply.started":"2023-07-24T20:24:39.051899Z","shell.execute_reply":"2023-07-24T20:24:57.033025Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:24:57.035833Z","iopub.execute_input":"2023-07-24T20:24:57.036771Z","iopub.status.idle":"2023-07-24T20:24:57.075990Z","shell.execute_reply.started":"2023-07-24T20:24:57.036730Z","shell.execute_reply":"2023-07-24T20:24:57.074918Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"audio_processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base-960h\")\naudio_model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\").to(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:24:57.079386Z","iopub.execute_input":"2023-07-24T20:24:57.080155Z","iopub.status.idle":"2023-07-24T20:25:06.680771Z","shell.execute_reply.started":"2023-07-24T20:24:57.080119Z","shell.execute_reply":"2023-07-24T20:25:06.679580Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)rocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa4c104929d34af995718f82e221efa1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31e09a33a00f416482cf1223743f56d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7e8e9e7524a4d44b64c4d1ef63eeacd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b5d3bff3f9a4c96a0d9590418366067"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"265bb5fde9f244558e3459bfdda2f5fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bc76b00caf54b488e01900f4ea2e8d9"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2Model: ['lm_head.weight', 'lm_head.bias']\n- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"vision_model = models.efficientnet_b7(pretrained=True)\nvision_model.cuda()\n_ = vision_model.eval()","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:25:06.682359Z","iopub.execute_input":"2023-07-24T20:25:06.682709Z","iopub.status.idle":"2023-07-24T20:25:09.546291Z","shell.execute_reply.started":"2023-07-24T20:25:06.682677Z","shell.execute_reply":"2023-07-24T20:25:09.545287Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B7_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B7_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/efficientnet_b7_lukemelas-dcc49843.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b7_lukemelas-dcc49843.pth\n100%|██████████| 255M/255M [00:01<00:00, 213MB/s]  \n","output_type":"stream"}]},{"cell_type":"code","source":"text_model = SentenceTransformer('sentence-transformers/LaBSE').to(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:25:09.547894Z","iopub.execute_input":"2023-07-24T20:25:09.548485Z","iopub.status.idle":"2023-07-24T20:25:29.419793Z","shell.execute_reply.started":"2023-07-24T20:25:09.548448Z","shell.execute_reply":"2023-07-24T20:25:29.418641Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)be010/.gitattributes:   0%|          | 0.00/391 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17c9e3eda7ca41e5bde455a850c95a93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1a4a6968496457087b0411f56435a69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/2_Dense/config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"085ef16413ce4a00b2de805ee4925ab8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/2.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0b7ce3591694119969405b0197de782"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)168ebbe010/README.md:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6539fa2ea2245559a691163ce05cf94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)8ebbe010/config.json:   0%|          | 0.00/804 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab50190d8a034b3db19d2a26958ebb7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6cbfbc0ffa9424395ea73de697a1365"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/1.88G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0ff594ff2af49d2af84454d0a2f6021"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdf0d2ff7c5849afb7b21faf655e67ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d41881d659f645a58809620db468a032"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)be010/tokenizer.json:   0%|          | 0.00/9.62M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"146838c707954b668d699261f9cdf3b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15578b36d1a44b8d987a901c2edbe115"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)168ebbe010/vocab.txt:   0%|          | 0.00/5.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99c7f9bce95c467ca6319f8947f26e9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ebbe010/modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"201cda2238414fcb98f1fa395a7e775d"}},"metadata":{}}]},{"cell_type":"code","source":"data_path = \"/kaggle/input/common-voice-dataset-version-4/data-file/train.tsv\"\naudio_path = \"/kaggle/input/common-voice-dataset-version-4/new-clip\"\ndata_train = pd.read_csv(data_path,comment='#',sep=\"\\t\")","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:25:29.421937Z","iopub.execute_input":"2023-07-24T20:25:29.422389Z","iopub.status.idle":"2023-07-24T20:25:30.987997Z","shell.execute_reply.started":"2023-07-24T20:25:29.422320Z","shell.execute_reply":"2023-07-24T20:25:30.986917Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"len(data_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:25:30.989426Z","iopub.execute_input":"2023-07-24T20:25:30.991369Z","iopub.status.idle":"2023-07-24T20:25:30.998127Z","shell.execute_reply.started":"2023-07-24T20:25:30.991315Z","shell.execute_reply":"2023-07-24T20:25:30.997043Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"232975"},"metadata":{}}]},{"cell_type":"code","source":"data_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-24T12:20:09.829939Z","iopub.execute_input":"2023-07-24T12:20:09.830619Z","iopub.status.idle":"2023-07-24T12:20:09.856188Z","shell.execute_reply.started":"2023-07-24T12:20:09.830574Z","shell.execute_reply":"2023-07-24T12:20:09.855080Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                           client_id  \\\n0  4f29be8fe932d773576dd3df5e111929f4e22242232245...   \n1  4f29be8fe932d773576dd3df5e111929f4e22242232245...   \n2  4f29be8fe932d773576dd3df5e111929f4e22242232245...   \n3  4f29be8fe932d773576dd3df5e111929f4e22242232245...   \n4  4f29be8fe932d773576dd3df5e111929f4e22242232245...   \n\n                           path  \\\n0  common_voice_en_19664034.mp3   \n1  common_voice_en_19664035.mp3   \n2  common_voice_en_19664037.mp3   \n3  common_voice_en_19664038.mp3   \n4  common_voice_en_19664040.mp3   \n\n                                            sentence  up_votes  down_votes  \\\n0  These data components in turn serve as the \"bu...         2           0   \n1  The church is unrelated to the Jewish politica...         3           0   \n2  The following represents architectures which h...         2           0   \n3  Additionally, the pulse output can be directed...         2           0   \n4  The two are robbed by a pickpocket who is losi...         3           0   \n\n        age gender accent  \n0  thirties   male    NaN  \n1  thirties   male    NaN  \n2  thirties   male    NaN  \n3  thirties   male    NaN  \n4  thirties   male    NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>client_id</th>\n      <th>path</th>\n      <th>sentence</th>\n      <th>up_votes</th>\n      <th>down_votes</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>accent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4f29be8fe932d773576dd3df5e111929f4e22242232245...</td>\n      <td>common_voice_en_19664034.mp3</td>\n      <td>These data components in turn serve as the \"bu...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>thirties</td>\n      <td>male</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4f29be8fe932d773576dd3df5e111929f4e22242232245...</td>\n      <td>common_voice_en_19664035.mp3</td>\n      <td>The church is unrelated to the Jewish politica...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>thirties</td>\n      <td>male</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4f29be8fe932d773576dd3df5e111929f4e22242232245...</td>\n      <td>common_voice_en_19664037.mp3</td>\n      <td>The following represents architectures which h...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>thirties</td>\n      <td>male</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4f29be8fe932d773576dd3df5e111929f4e22242232245...</td>\n      <td>common_voice_en_19664038.mp3</td>\n      <td>Additionally, the pulse output can be directed...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>thirties</td>\n      <td>male</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4f29be8fe932d773576dd3df5e111929f4e22242232245...</td>\n      <td>common_voice_en_19664040.mp3</td>\n      <td>The two are robbed by a pickpocket who is losi...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>thirties</td>\n      <td>male</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_train['sentence'][4]","metadata":{"execution":{"iopub.status.busy":"2023-07-24T12:00:08.046946Z","iopub.status.idle":"2023-07-24T12:00:08.047339Z","shell.execute_reply.started":"2023-07-24T12:00:08.047122Z","shell.execute_reply":"2023-07-24T12:00:08.047140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(Audio(f\"{audio_path}/{data_train['path'][4]}\"))","metadata":{"execution":{"iopub.status.busy":"2023-07-24T12:00:08.048470Z","iopub.status.idle":"2023-07-24T12:00:08.049136Z","shell.execute_reply.started":"2023-07-24T12:00:08.048719Z","shell.execute_reply":"2023-07-24T12:00:08.048780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio_file = AudioSegment.from_file(f\"{audio_path}/{data_train['path'][4]}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-23T21:40:26.220448Z","iopub.execute_input":"2023-07-23T21:40:26.220885Z","iopub.status.idle":"2023-07-23T21:40:26.997419Z","shell.execute_reply.started":"2023-07-23T21:40:26.220851Z","shell.execute_reply":"2023-07-23T21:40:26.996382Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"len(audio_file.get_array_of_samples())","metadata":{"execution":{"iopub.status.busy":"2023-07-23T21:40:54.524721Z","iopub.execute_input":"2023-07-23T21:40:54.525393Z","iopub.status.idle":"2023-07-23T21:40:54.531952Z","shell.execute_reply.started":"2023-07-23T21:40:54.525357Z","shell.execute_reply":"2023-07-23T21:40:54.530590Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"223488"},"metadata":{}}]},{"cell_type":"code","source":"audio_file.frame_rate","metadata":{"execution":{"iopub.status.busy":"2023-07-23T21:45:42.188114Z","iopub.execute_input":"2023-07-23T21:45:42.188482Z","iopub.status.idle":"2023-07-23T21:45:42.201649Z","shell.execute_reply.started":"2023-07-23T21:45:42.188452Z","shell.execute_reply":"2023-07-23T21:45:42.198406Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"48000"},"metadata":{}}]},{"cell_type":"code","source":"# preprocess sentence\ndef preprocess_sentence(sentence):\n    sentence = sentence.lower()\n    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n    sentence = sentence.strip()\n    return sentence","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:25:30.999628Z","iopub.execute_input":"2023-07-24T20:25:31.000744Z","iopub.status.idle":"2023-07-24T20:25:31.009544Z","shell.execute_reply.started":"2023-07-24T20:25:31.000706Z","shell.execute_reply":"2023-07-24T20:25:31.008262Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"preprocess_sentence(data_train['sentence'][10])","metadata":{"execution":{"iopub.status.busy":"2023-07-23T21:28:05.348055Z","iopub.execute_input":"2023-07-23T21:28:05.348483Z","iopub.status.idle":"2023-07-23T21:28:05.356027Z","shell.execute_reply.started":"2023-07-23T21:28:05.348448Z","shell.execute_reply":"2023-07-23T21:28:05.354821Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'what did you think of that trip'"},"metadata":{}}]},{"cell_type":"code","source":"def get_image_embedding(path):\n    image = cv2.imread(path)\n    image_tensor = torch.from_numpy(image)\n    image_tensor = image_tensor.unsqueeze(0)\n    image_tensor = image_tensor.permute(0, 3, 1, 2)\n    image_tensor = image_tensor.to(device)\n    image_tensor = image_tensor.float()\n    with torch.no_grad():\n        output = vision_model(image_tensor)\n        embedding = output[0].cpu()\n        return embedding","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:25:31.013552Z","iopub.execute_input":"2023-07-24T20:25:31.013864Z","iopub.status.idle":"2023-07-24T20:25:31.023557Z","shell.execute_reply.started":"2023-07-24T20:25:31.013831Z","shell.execute_reply":"2023-07-24T20:25:31.022620Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"start_id = 200000","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:25:31.025193Z","iopub.execute_input":"2023-07-24T20:25:31.025555Z","iopub.status.idle":"2023-07-24T20:25:31.036737Z","shell.execute_reply.started":"2023-07-24T20:25:31.025522Z","shell.execute_reply":"2023-07-24T20:25:31.035636Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def pipeline_for_common_voice(dataset, limit, split, valid_ids, part_number, start_idx=0):\n    data_v1 = {}\n    counter = 0\n    j = 0\n    max_id = 0\n    if start_idx == 0: \n        val_ids_final = valid_ids\n    else:\n        for i, item in enumerate(valid_ids):\n            if item == start_idx:\n                j = i\n                break\n        val_ids_final = valid_ids[(j + 1):]\n    for audio_idx in tqdm(val_ids_final):\n        if counter == 0:\n            print(f'start_idx {audio_idx}')\n        if counter % 100 == 0:\n            torch.cuda.empty_cache()\n            gc.collect()\n            torch.cuda.ipc_collect()\n        if counter == limit + 50:\n            max_id = audio_idx\n            break\n        try:\n            file_path = f\"{audio_path}/{dataset['path'][audio_idx]}\"\n            inner_data = {}\n            inner_data['id'] = start_id + audio_idx\n            inner_data['file_path'] = file_path\n            inner_data['audio_idx'] = audio_idx\n\n            audio_file = AudioSegment.from_file(file_path)\n            samples = np.array(audio_file.get_array_of_samples())\n            samples = samples.reshape(-1, audio_file.channels)\n            samples = samples / np.max(np.abs(samples))\n            samples = samples.squeeze()\n\n            samples = resampy.resample(samples, audio_file.frame_rate, 16000)\n            audio = torch.from_numpy(samples)\n            inputs = audio_processor(audio, sampling_rate=16000, return_tensors=\"pt\").to(device)\n            with torch.no_grad():\n                outputs = audio_model(**inputs)\n            last_hidden_states = outputs.last_hidden_state.squeeze(0)\n            embeddings = last_hidden_states.mean(dim=0)\n            inner_data['audio_embedding'] = embeddings.cpu()\n            inner_data['text'] = preprocess_sentence(dataset['sentence'][audio_idx])\n            data_v1[start_id + audio_idx] = inner_data\n            counter += 1\n        except Exception as e:\n            print(e)\n            print(dataset['path'][audio_idx])\n            continue\n    print(f'max id {max_id}')\n    data_v2 = {}\n    counter = 0\n    for audio_idx in tqdm(val_ids_final):\n        if counter == limit:\n            break\n\n        if start_id + audio_idx not in data_v1.keys():\n             continue\n                \n        if counter % 100 == 0:\n            torch.cuda.empty_cache()\n            gc.collect()\n            torch.cuda.ipc_collect()\n\n        try:\n            file_path = f\"{audio_path}/{dataset['path'][audio_idx]}\"\n            y, sr = librosa.load(file_path)\n            spec = librosa.stft(y)\n            spec_db = librosa.amplitude_to_db(abs(spec))\n            \n            plt.clf()\n            librosa.display.specshow(spec_db, x_axis='time', y_axis='log')\n            plt.xlabel('')\n            plt.ylabel('')\n            plt.tight_layout()\n\n            saved_path = f'spec.png'\n            plt.savefig(saved_path, bbox_inches='tight', pad_inches=0)\n            image_embeddings = get_image_embedding(saved_path)\n            data_v2[start_id + audio_idx] = data_v1[start_id + audio_idx].copy()\n            data_v2[start_id + audio_idx]['image_embedding'] = image_embeddings\n            counter += 1\n\n        except Exception as e:\n            print(e)\n            print(dataset['path'][audio_idx])\n            continue\n    data_v3 = {}\n    counter = 0\n    for audio_idx in tqdm(val_ids_final):\n        if start_id + audio_idx not in data_v2.keys():\n            continue\n        if counter == limit:\n            break\n        try:\n            text_embeddings = text_model.encode(data_v2[start_id + audio_idx]['text'])\n            data_v3[start_id + audio_idx] = data_v2[start_id + audio_idx].copy()\n            data_v3[start_id + audio_idx]['text_embedding'] = torch.tensor(text_embeddings)\n            counter += 1\n        except Exception as e:\n            print(e)\n            print(dataset['path'][audio_idx])\n            continue\n    with open(f'pretrained_embeddings_common_voice_{split}_part_{part_number}.pkl', 'wb') as f:\n        pickle.dump(data_v3, f)\n    print(f'max id {max_id}')\n    return max_id","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:25:31.040074Z","iopub.execute_input":"2023-07-24T20:25:31.040473Z","iopub.status.idle":"2023-07-24T20:25:31.065300Z","shell.execute_reply.started":"2023-07-24T20:25:31.040445Z","shell.execute_reply":"2023-07-24T20:25:31.064257Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def find_proper_audios(dataset):\n    audio_idxs = []\n    for audio_idx in tqdm(range(len(dataset))): \n        file_path = f\"{audio_path}/{dataset['path'][audio_idx]}\"\n        if os.path.exists(file_path):\n            audio_idxs.append(audio_idx)\n    print(f'len of audio idxs {len(audio_idxs)}')\n    return audio_idxs","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:25:31.066665Z","iopub.execute_input":"2023-07-24T20:25:31.067380Z","iopub.status.idle":"2023-07-24T20:25:31.082110Z","shell.execute_reply.started":"2023-07-24T20:25:31.067323Z","shell.execute_reply":"2023-07-24T20:25:31.080819Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_valid_ids = find_proper_audios(data_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T12:27:35.108910Z","iopub.execute_input":"2023-07-24T12:27:35.109341Z","iopub.status.idle":"2023-07-24T12:39:40.813767Z","shell.execute_reply.started":"2023-07-24T12:27:35.109308Z","shell.execute_reply":"2023-07-24T12:39:40.812776Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"100%|██████████| 232975/232975 [12:05<00:00, 321.04it/s]","output_type":"stream"},{"name":"stdout","text":"len of audio idxs 178211\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# max_idx = pipeline_for_common_voice(data_train, 5000, 'train', train_valid_ids, part_number=1, start_idx=0)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T22:41:24.387247Z","iopub.execute_input":"2023-07-23T22:41:24.387622Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  0%|          | 0/178211 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"start_idx 0\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 5100/178211 [26:59<15:16:17,  3.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"max id 18105\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/178211 [00:01<81:40:06,  1.65s/it]/tmp/ipykernel_28/3664502682.py:77: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n  3%|▎         | 4605/178211 [51:40<37:40:45,  1.28it/s]","output_type":"stream"}]},{"cell_type":"code","source":"# max_idx = pipeline_for_common_voice(data_train, 5000, 'train', train_valid_ids, part_number=2, start_idx=max_idx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# max_idx = pipeline_for_common_voice(data_train, 5000, 'train', train_valid_ids, part_number=3, start_idx=max_idx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# max_idx = pipeline_for_common_voice(data_train, 5000, 'train', train_valid_ids, part_number=4, start_idx=max_idx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# max_idx = pipeline_for_common_voice(data_train, 5000, 'train', train_valid_ids, part_number=5, start_idx=max_idx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# max_idx = pipeline_for_common_voice(data_train, 5000, 'train', train_valid_ids, part_number=6, start_idx=max_idx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# max_idx = pipeline_for_common_voice(data_train, 5000, 'train', train_valid_ids, part_number=7, start_idx=max_idx)","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  3%|▎         | 5050/147855 [29:29<13:54:08,  2.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"max id 71054\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/147855 [00:04<177:53:54,  4.33s/it]/tmp/ipykernel_28/998898637.py:77: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n  0%|          | 179/147855 [02:05<28:40:00,  1.43it/s]","output_type":"stream"}]},{"cell_type":"code","source":"# max_idx = 71054","metadata":{"execution":{"iopub.status.busy":"2023-07-24T12:39:40.815944Z","iopub.execute_input":"2023-07-24T12:39:40.816312Z","iopub.status.idle":"2023-07-24T12:39:40.823039Z","shell.execute_reply.started":"2023-07-24T12:39:40.816277Z","shell.execute_reply":"2023-07-24T12:39:40.822119Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# max_idx = pipeline_for_common_voice(data_train, 5000, 'train', train_valid_ids, part_number=8, start_idx=max_idx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# max_idx = pipeline_for_common_voice(data_train, 5000, 'train', train_valid_ids, part_number=9, start_idx=max_idx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# max_idx = pipeline_for_common_voice(data_train, 5000, 'train', train_valid_ids, part_number=10, start_idx=max_idx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_data_path = \"/kaggle/input/common-voice-dataset-version-4/data-file/dev.tsv\"\ndata_dev = pd.read_csv(dev_data_path,comment='#',sep=\"\\t\")","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:25:31.083880Z","iopub.execute_input":"2023-07-24T20:25:31.084275Z","iopub.status.idle":"2023-07-24T20:25:31.197217Z","shell.execute_reply.started":"2023-07-24T20:25:31.084239Z","shell.execute_reply":"2023-07-24T20:25:31.196105Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"len(data_dev)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:25:31.199091Z","iopub.execute_input":"2023-07-24T20:25:31.199512Z","iopub.status.idle":"2023-07-24T20:25:31.206895Z","shell.execute_reply.started":"2023-07-24T20:25:31.199473Z","shell.execute_reply":"2023-07-24T20:25:31.205915Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"15531"},"metadata":{}}]},{"cell_type":"code","source":"dev_valid_ids = find_proper_audios(data_dev)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T20:25:31.208667Z","iopub.execute_input":"2023-07-24T20:25:31.209350Z","iopub.status.idle":"2023-07-24T20:26:05.158692Z","shell.execute_reply.started":"2023-07-24T20:25:31.209297Z","shell.execute_reply":"2023-07-24T20:26:05.157639Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"100%|██████████| 15531/15531 [00:33<00:00, 457.66it/s]","output_type":"stream"},{"name":"stdout","text":"len of audio idxs 3492\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"max_idx = pipeline_for_common_voice(data_dev, 5000, 'validation', dev_valid_ids, part_number=1, start_idx=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_path = \"/kaggle/input/common-voice-dataset-version-4/data-file/test.tsv\"\ndata_test = pd.read_csv(test_data_path,comment='#',sep=\"\\t\")\nlen(data_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T21:40:01.221241Z","iopub.execute_input":"2023-07-24T21:40:01.222213Z","iopub.status.idle":"2023-07-24T21:40:01.347402Z","shell.execute_reply.started":"2023-07-24T21:40:01.222176Z","shell.execute_reply":"2023-07-24T21:40:01.346276Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"15531"},"metadata":{}}]},{"cell_type":"code","source":"test_valid_ids = find_proper_audios(data_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T21:40:01.349140Z","iopub.execute_input":"2023-07-24T21:40:01.350110Z","iopub.status.idle":"2023-07-24T21:40:34.980683Z","shell.execute_reply.started":"2023-07-24T21:40:01.350065Z","shell.execute_reply":"2023-07-24T21:40:34.978311Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"100%|██████████| 15531/15531 [00:33<00:00, 461.98it/s]","output_type":"stream"},{"name":"stdout","text":"len of audio idxs 2197\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"max_idx = pipeline_for_common_voice(data_test, 5000, 'test', test_valid_ids, part_number=1, start_idx=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mix all files pretrained\nimport pickle\nfrom IPython.display import FileLink\n\ndata = {'train': {}, 'test': {}, 'validation': {}}\nfor i in range(1, 11):\n    with open(f'pretrained_embeddings_common_voice_train_part_{i}.pkl', 'rb') as f:\n        data['train'].update(pickle.load(f))\nwith open(f'pretrained_embeddings_common_voice_test_part_1.pkl', 'rb') as f:\n    data['test'].update(pickle.load(f))\nwith open(f'pretrained_embeddings_common_voice_validation_part_1.pkl', 'rb') as f:\n    data['validation'].update(pickle.load(f))\n\nwith open(f'pretrained_embeddings_common_voice.pkl', 'wb') as f:\n    pickle.dump(data, f)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T22:41:27.925080Z","iopub.execute_input":"2023-07-24T22:41:27.925541Z","iopub.status.idle":"2023-07-24T22:42:08.551943Z","shell.execute_reply.started":"2023-07-24T22:41:27.925504Z","shell.execute_reply":"2023-07-24T22:42:08.550930Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"FileLink('pretrained_embeddings_common_voice.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-07-24T22:43:26.177281Z","iopub.execute_input":"2023-07-24T22:43:26.177756Z","iopub.status.idle":"2023-07-24T22:43:26.186141Z","shell.execute_reply.started":"2023-07-24T22:43:26.177722Z","shell.execute_reply":"2023-07-24T22:43:26.184881Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/pretrained_embeddings_common_voice.pkl","text/html":"<a href='pretrained_embeddings_common_voice.pkl' target='_blank'>pretrained_embeddings_common_voice.pkl</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"with open(f'pretrained_embeddings_common_voice.pkl', 'rb') as f:\n    data = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T22:42:56.330336Z","iopub.execute_input":"2023-07-24T22:42:56.330802Z","iopub.status.idle":"2023-07-24T22:43:17.992636Z","shell.execute_reply.started":"2023-07-24T22:42:56.330768Z","shell.execute_reply":"2023-07-24T22:43:17.991688Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(len(data['train']))\nprint(len(data['validation']))\nprint(len(data['test']))","metadata":{"execution":{"iopub.status.busy":"2023-07-24T22:47:46.537564Z","iopub.execute_input":"2023-07-24T22:47:46.537985Z","iopub.status.idle":"2023-07-24T22:47:46.545254Z","shell.execute_reply.started":"2023-07-24T22:47:46.537953Z","shell.execute_reply":"2023-07-24T22:47:46.543728Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"50000\n3492\n2197\n","output_type":"stream"}]},{"cell_type":"code","source":"random_key = random.choice(list(data['train'].keys()))\ndata['train'][random_key]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}